#SLIDE 1
Let's introduce a practical example of backpropogation, where we will start with this picture of a bird.  To simplify this a little bit, we're going to take the hypothetical situation where we have downscaled this image into only two greyscale pixels, taking the average of all pixels (of course you wouldn't really do this, but I can only fit so many nodes on this example!).  After we walk through the two-pixel case, we'll talk about the vectorized version of this that would include all pixels.

#SLIDE 2
In our hypothetical, we're going to try and establish if this picture is a bird or... lets say, a car, and we'll use our hinge loss function.  As always, the first step of this is to create our graph.

#SLIDE 3
First on our graph are the four input weights - we would have two weights for bird, and two weights for car (one for each pixel).  These are the values we'll multiply by each pixel.  In this case, I've arbitrarily chosen some initial weights for these (see the -2, -1, 1 and -5 - these would be the equivalent of starting with random weights). 

#SLIDE 4
Here we add our pixel values.  In this case, we have pixel 1 and pixel 2, representing the two giant greyscale pixels we created to represent the bird.  They have pixel values of 3 and 2.

#SLIDE 5
The first computational function we use is multiplication, where we multiply each weight by it's respective pixel.  To make this easier on the eyes, I'm going to move a few of our input boxes around to group the weights for each pixel.  Red boxes are still representing the weights for bird, and blue car weights.  Now both weights at the bottom are representative of weights for pixel 2, and the two at the top are for pixel 1.

#SLIDE 6
The first function we need to do is multiply - this is a linear model with a SVM hinge loss we're trying to replicate.  We multiply the weights for each class (bird and car) by their respective pixels.  This is repeated twice, once for each pixel, for a total of four multiplication computations.

#SLIDE 7
Following our linear approach, we now add the multiplicative values for each class to get the final class scores for both bird and car.  This is represented by two addition computations.  In this graph, the blue circular node would contain our final score for the car class, and the red circular node would contain our final score for the bird class.  

#SLIDE 8
Now, we're ready to calculate the loss function.  You'll recall in the SVM loss we only calculate loss for the *incorrect* cases.  We only have to apply this equation once.  The first step in this loss function is subtracting the bird score (which we know is correct), s_yi, from the incorrect car score, s_j.

#SLIDE 9
Which looks like this - where the subtraction node represents the sj-syi in our loss function.

#SLIDE 10
Now, we have an addition function, representative of the epsilon in our hinge loss.  Because epsilon is a hyperparameter, we also need to represent it here.

#SLIDE 11
Finally, we have our max function, which is what gives us our final loss.  We'll represent the final output of this example as f.

#SLIDE 12
With that we've now constructed our computational graph for this simplified case with only two pixels.  Now, we're going to do what's called a forward pass.  In this forward pass, we're going to solve for f by following each step of the graph forward, starting from the weights and pixels.

#SLIDE 13
Let's start at the top.  This first multiplication computation is the randomly initiatlized weight for W_1_1, or the weight for bird and pixel 1.  The -2 here is entirely random to give us a starting point.  Pixel 1 is the 3, representative of our bird pixel.  Multiplying these two together would give us a -6 for the forward pass.  (Note - in case you're confused, look in the boxes at the left - I've copied the weights and pixel values into them for reference).

#SLIDE 14
We then repeat this for every multiplication node.  Note that I am representing the outputs of each node in red, along the arrow coming out from the node.

#SLIDE 15
Now, we do our first addition node.  Same logic here - the outputs of nodes are in red along the output.  The blue addition computation would resolve to 3 + -10, or -7.

#SLIDE 16
And the red addition node would be -6 + -2, or -8.

#SLIDE 17
For subtraction, following our loss function, we want sj - syi, or the wrong score (blue, car) minus the right score (red, bird).  This resolves to -7 (the output of the car addition node) - -8 (the output of the bird addition node), or 1.

#Slide 18
Next, we add epsilon.  In this case we'll assume epsilon = 1.  So, 1 + 1, or 2.

#Slide 19
Finally, we take the max of 0 and 2, which results in 2 as our final output for f in this case.

#Slide 20
So - this was our first guess at Weights, and they were random so we know that they probably aren't optimal.  So, how do we update the weights to try and get a better prediction for our bird in this case?  This is the magic of backpropogation - so let's head backwards through this graph.  We'll start focusing in on just the first step here.

#Slide 21
Fundamentally, at each step of the process we are trying to solve for how much the next node in our graph will change by, given a one-unit change in a precursor node. The first of these - highlighted in purple - is simple: if you increase the output of the max function by 1, then our final loss function f will also change by one.  We'll be answering this same question for each node across the full network.  The first question - highlighted by a question mark - is if we change the output of the addition computation, what would the change in the output of the max function be?  Let's zoom in on this first case for a moment.

#Slide 22
In this zoomed in part of our graph, we are trying to solve for the downstream gradient from the max computation node to the addition computation node, represented by the question mark on the graph.  This can intuitively be understood as the change in the max computation given a change in the addition computation. This is sometimes referred to as a max gate - to help build intuition, I'm going to label a few things.  First, you'll see the value coming from the addition to the max function is now labeled as "X".  So, in our forward propogation, we had X = 2.  Additionally, you'll see the computation in the max node is now max(0, X), which is reflective of our loss functionn in the upper-right of the screen.  The reason max functions are referred to as gates is becuase of how they operate in back-propogation.  In this case, the downstream gradient we would pass is either equal to 0 (it doesn't matter if you change the output of the addition function if it's less than 0 - it would stay 0), or 1 (an increase in the output of the addition node by 1 would increase the max node output by 1 if the output is greater than 0).  

#Slide 23
In this case, our X was 2, which is greater than 0, and thus the gradient we pass back would be 1, because our incoming gradient from the downstream f is 1 (i.e., we pass the entire gradient back - a 1 unit change in our addition function would result in a one unit change in the final output f).  If X had been a negative value, this would resolve to a 0.

#Slide 24
Ok, back to our full graph.  In this case, this backpropogation step has a gradient of 1 being passed back to the addition computation from the max computation - i.e., the purple 1 in the red box can be understood as "if we increase the output of the addition by 1, then the final value f will also increase by 1".  This is also called a local gradient for the addition node, which is df / dx, or 1 - that is, a one unit increase in the input to the addition node results in a one unit increase in the function f.  We now are going to move back another step to solve for the change in the addition computation given a change in the subtraction computation.  

#Slide 25
The increas in f if the output of our subtraction node increases by 1 is fairly intuitive - i.e., if the value goes up by 1 here, it will also go up by 1 in the following addition node, and thus the local gradient resolves to a 1, shown bolded and purple in the red box here.

#Slide 26
Let's go back another step now.  Here, we want to solve for what the change in function f would be if we increased the addition function in red.  The forward pass output of this addition was -8.  Let's start here by formally defining a few things.  First, we're going to define the upstream gradient - the gradient we just solved for, represented underlined and in purple here - as U.  So, in this case, U = 1.  

#Slide 27
Next, we need to solve for the top local downstream gradient - again, the expected change in f if the *red* addition computation node was to increase by one.  The red node represents the score for "true", or the bird.  So, in our loss function, if the red addition node output increases, the value of the subtraction will *decrease* - i.e., we're subtracting red from blue.  So, the local gradient in this top case is -1.  We'll define that as L0 (where 0 represents the red node gradient).  Ultimately, we want to calculate the impact a change in our addition node would have on function f, which is represented by our purple question mark on this slide.  The way these are calculated is by multiplying local and upstream gradients - i.e., L0 and U that we just calculated.

#Slide 28
So, to calculate the purple question mark, we just multiply L0 - our local gradient of -1 - by the upstream gradient - 1. That gives us -1, and thus our first gradient is -1. Intuitively, this means that if the score we assign to bird increases by 1, we would expect a decrease in our final loss f by 1.  Which is exactly what we would want!

#Slide 29
Now we can move onto our second gradient - how the value of this subtraction node changes if there is a change in the *blue* addition node.  This node represents the car value.  Just like before, we are trying to solve for how function f would change if there was a one-unit increase in the second input into the subtraction computation - this is represented by the question mark.  First, we know that our upstream gradient in this case is 1 - i.e., the incoming gradient we already solved for (that is, U = 1).  In this case, if we have a one-unit increase in the incoming number from the blue addition node, we actually have a one-unit *increase* in our subtraction function.  That is, we're increaing sj - the "incorrect" score of car.  As before, this means our local gradient is 1 - i.e., L1 = 1.

#Slide 30
Applying the same logic as last time, we'll multiply our local gradient L1 - 1 - by our upstream gradient U of 1, which gives us 1 for our downstream gradient. Intuitively, this means that if the score we calculate for "Car" increases by 1, our loss function will also increase by one.

#Slide 31
Backpropogation works by applying this strategy for every node across the network.  As a further example, I'm only going to follow the red addition node further back (i.e., the caclulation for the bird score).  Let's solve for the top branch first, denoted by the large purple question mark.  The number we are trying to solve for is, given a change in the output of the top multiplication computation (circled in red), what is the change in the final function f?  In this case, we know that the gradient of an addition function is going to be equal to 1 - i.e., an increase of 1 in either input results in a change of the output of 1.  So, L_0 (our top local gradient) would simply be 1. The incoming gradient in this case - what we solved for on the last few slides - is a negative 1.  So, the final gradient we pass here is -1.

#Slide 32
We can do the same thing for the bottom gradient - in this case, it's the same as the top, as the gradient of the addition function is the same for both paths.  

#Slide 33
Finally we've chained all the way back to the gradient we're trying to solve for - what the expected change in f would be if we changed the first weight (the weight for the first pixel for bird).  

#Slide 34
In our forward pass, the input value of pixel 1 was 3, the underlined value in red; the weight 1 for bird was -2.  So, just like last time, we need to solve for the upstream and local gradients.  This time, our upstream was -1.  A multiplicative gradient resolves to the inverse input - i.e., intuitively an increase of 1 in our weight (from -2 to -1) would result in an increase of 3 (our pixel value). So, if we're trying to solve for the top path (that is, the weight - the one we care about), the *local* gradient (L_0) is equal to 3.

#Slide 35
Just like before, we multiply this local gradient by the upstream gradient (U = -1), and we get a -3.  This is the chain-rule solution to the gradient for the first weight in this example!  Note that we could solve for the gradient of pixel 1 - i.e., if the pixel value changed what the resulting change in the function would be - but we don't really care in this case, as we aren't adjusting pixel values - only weights.

#Slide 36
If we move to the bottom, we can repeat this exact same operation to solve for the gradient of the second bird weight - in this case, the weight associated with the second pixel for bird.  Pause the video here for a minute if you want to try annd solve this on your own (I recommend it!), otherwise in a second I'm going to go to the next slide with the solution.

#Slide 37
And, viola!  In this case, we would have a expected change in our final function f of -2 if this parameter increased by 1.  

#Slide 38
I went ahead and solved this out for the two other weights - Car pixel 1 weight and pixel 2 weight - here.  So, ultimately we have the four values we care about - the gradients for each of our weights (-3, 3, 2 and -2).  So, why do we care?  What is so special about these four numbers that we just spent the better part of a lecture solving for?

#Slide 39
Let's go back to our goal and what all this means.  We started with four weights at the very beginning of our backpropoagation, represented in the boxes here - -2, 1, -5 and -1.   When we solved with those weights, we end up with a score of -7 for car, and -8 for bird.  So, car is bigger - thus, we would pick car as our class for this bird picture.  That's not great, becuase we know the image is a bird, so we want our loss value to be high (i.e., "badness is high".)

#Slide 40
When we calculated the full graph, we also had a final output of 2 - i.e., our loss was 2.  Remember, higher values are worse - optimally, we want our loss to be 0 (or even negative for some loss functions).

#Slide 41
The gradient - i.e., the four weights we just calculated - tells us how we would expect our loss to change if we changed each of the weights by positive one.  So, if all we did was increase weight 1 by 1, the final loss value would be expected to be -1 (i.e., it's 2 now, and we expect it would decrease by 3).  So, that would be good!  At the same time, if we increased the first car weight (W2_1) by 1, we would expect an increase in our loss function of 3 - that's no good.

#Slide 42
So, what we do is we add the INVERSE of the gradient to our weights, to get a new set of weights to test.  Take the first row for example. We know from our gradient that if we increase weight 1 for bird by 1, we expect a decrease in our loss function of 3, which is what we want.  So, by taking the inverse of the gradient, we are going to increase weight 1 by 3 - i.e., an even larger positive increase, which we are hypothesizing will give us what we want - a lower loss function.  In this case, this means the new weight for Bird would be 1.

#Slide 43
We repeat this process for each weight - updating them based on the gradient.  So, like that, we have a new set of weights to test, and a set of weights our gradient specifically informs us are likely going to produce a lower loss.

#Slide 44
We can plug these weights back in and do a new forward pass to see if the loss function is better.  Remember, last time our loss function was 2.  The new weights are now on the left, and the solutions for each step of the forward propogation are in red.  If we work left to right, you can see that now our max function resolves to 0 - i.e., our final loss is 0, which is as good as it gets in this case.  So, our model would not be able to improve any further past this point, and would have a perfect classificaiton (it is now, in fact, classifying a bird as a bird).  From this point, we could back-propogate again to further refine our weights, but it wouldn't make any difference here, as there is no more improvement that can be accomplished!  In more complex models with many, many more parameters, you will have to do back-propogation dozens, hundreds, thousands, or even more times.