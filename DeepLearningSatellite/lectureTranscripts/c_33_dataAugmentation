#SLIDE
A hugely popular technique for improving how generalizable models are is data augmentation.  What you see now is our basic training strategy, in which we have our input dataset (made up of images and classes), a model which we apply to the images, and then a loss function which takes the model score estimates in, and contrasts them to the true class name (i.e., stopsign).  
#SLIDE
Data Augmentation relies on adding a new step into this pipeline, which is an image transformation step.  Essentially, a model (or set of models) is defined which change the makeup of the image, with the goal of creating new views of what the image might be.  I.e., in this case, after the transofrmation the stop sign is still a stopsign, but in black and white and at a slightly different angle. The basic idea here is that we can synthetically create more data - i.e., augment our data - with additional examples of a class (here, a stopsign) by applying transformations that might approximate other, unseen images.
#SLIDE
There are a number of very common augmentation strategies that you will come across.  Flipping images is one of the most frequently seen - i.e., a horse is still a horse, no matter what direction it's facing.  If the original horse was on the left, our network might be biased towards detecting horses only if they are facing left.  By augmenting our data by flipping this image to face right, we may be able to better detect images of horses beyond what we had in our data.  
#SLIDE
The same basic principals apply for a range of other transformations - i.e., increasing the contrast and brightness of the input images, or cropping.  During training, you can also apply any combination of these modifications, or more.  The fundamental thing to keep in mind when applying augmentations is that you want the network to learn based on examples that you might expect to see in your test dataset, even though you won't be able to train on it!