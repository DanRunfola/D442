#SLIDE
Ok - let's move on to talk about Generative Adversarial Networks, or GANs.  GANs are fundamentally different than either the PixelCNN, PixelRNN, or VAE approaches, in that they do not seek to solve for the probability distributions.  Instead, they seek to sample the space created by Z through a 2-player game, where both of our players are neural networks.
#SLIDE
The way we'll actually train a GAN relies on our two players.  The first player is our generator network, which is a neural network we architect to generate real-looking images (with an input of Z, our random noise).  The second network is our discriminator network, which tries to distinguish between real and fake images. 
#SLIDE
The intuition of the setup of a GAN is fairly straightforward - we want to take some random noise in (Z), run it through a generator network that learns to take random noise and transform it into something similar to our input training data, and finally output an image.  These outputs would represent a sample from our training distribution - not the training dataset itself, but the distribution of the data. 
#SLIDE
The complete architecture of a GAN looks like this.  First (at the lower-left), we have our input Z - which is, again, just random noise.  We have some generator network that takes that noise and transforms it into (eventually) pictures that look something like a cat.  These fake images are then passed into the discriminator network, alongside a batch of real images of cats.  The discriminator network then attempts to correctly classify each cat as real or fake, which is the final output of the GAN.  The idea is if we have a very good discriminator, it can do a good job of determining real vs. fake - then, if our generator network does well and can fool the discriminator, then the discriminator will change more, causing the generator to change more... and so on.
#SLIDE
Ok - so now let's think about how this would actually be trained.  Let's start with the first case - loss is low, indicating that the discriminator network is doing a good job distinguishing between fake and real cats.  This is good news for our discriminator, but bad news for our generator!  So - if loss is low, we want our discriminator to change relatively little, but our generator to change a lot.  Conversely, if our loss is high, we want our discriminator to change more rapidly, and our generator can change slower.  This is done following a minimax objective function, in whcih we alternate between a gradient ascent (yes, ascent!) on the discriminator, and a gradient ascent on the generator, where we intentionally are seeking to maximize the likelihood of the discriminator being wrong.  While it's very interesting, I won't go into the details of the loss functions or backpropogation here, but you'll get a hands-on chance to work with these implementations in your assignment, and can also read through the Goodfellow piece shared in the lecture notes.  I definitely encourage those of you interested in a really clever implementation of a mini-max function to dig deeper.
#SLIDE
OK - let's talk a little more about the GAN architecture itself.  Remember, we have two networks: the generator and the discriminator.  It's very easy to reach some really implausible solutions in this case, so taking a lot of care to ensure your generator and discriminator are both well specified is important.  While a discriminator is essentially going to be a 'traditional' CNN, our generator is going to do some tricks we haven't seen before.
#SLIDE
The biggest new element is the idea of a transposed convolution.  Remember back to when we were discussing convolutional neural nets.  In the example on the screen, we have a 2x2 filter; the four values in the 2x2 filter are being summed (i.e., they all have equal weights of 1), and a value of 7 (the sum of all values) is added to our activation surface. 
#SLIDE
A transposed convolution does exactly the opposite.  Here, we have the number 7 in our activation surface, and we want to distribute that number 7 across the four pixels in red.  
#SLIDE
This is done by ascribing a weight to each cell of our filter, and then using those weights to (in this case, multiply) the input value on the activation surface to "upsample" from one pixel to four pixels.  The challenge in the context of a GAN is to find the weights that best result in an image as similar as possible to the input training data.
#SLIDE
There are a number of rules-of-thumb for how many layers to introduce into your networks (discriminating and generating), but effectiveness is very, very task-dependent, and identifying good architectures for GANs is a very active area of inquiry.  A few important ones are to use batchnormalization, avoid fully connected layers if you have a deep net, and to use leakyReLu in your discriminator and ReLU in your generator.  We know relatively little about the exact interactions between these approaches, but a deep dive into this topic is available in the lecture notes in the reading "Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks".
#SLIDE
There are hundreds of GANs out there tailored to different purposes, with some of the most impressive over the last year coming out of the NVIDIA and Google research groups.  Increasingly, transfer learning potential appears to be emerging with GANs, suggesting that a GAN designed for one topic area may be able to be extended to others, even if they are apparently far-afield.  This process of improvement is mirroring the evolution of convolutional classification algorithms so far, to the point where today you can download the trained network that generated the faces you see here off-the-shelf, in either pytorch or tensorflow implementations!