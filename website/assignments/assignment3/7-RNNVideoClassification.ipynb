{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd08e3a21d38ab9816cf2a4fb5b70910b2de32092d7fedca6365d5651d786256744",
   "display_name": "Python 3.8.5 64-bit ('data442': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "8e3a21d38ab9816cf2a4fb5b70910b2de32092d7fedca6365d5651d786256744"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "I have 50 frames.\nI want to capture every frame starting with 0, incrementing by 5.\nI will grab frame 0\nI will grab frame 5\nI will grab frame 10\nI will grab frame 15\nI will grab frame 20\nI will grab frame 25\nI will grab frame 30\nI will grab frame 35\nI will grab frame 40\nI will grab frame 45\n[[[ 39  40  30]\n  [ 32  33  23]\n  [ 27  28  18]\n  ...\n  [123 165 224]\n  [123 170 229]\n  [119 166 225]]\n\n [[ 37  38  28]\n  [ 32  33  23]\n  [ 27  28  18]\n  ...\n  [124 166 225]\n  [125 172 231]\n  [125 172 231]]\n\n [[ 31  32  22]\n  [ 30  31  21]\n  [ 30  31  21]\n  ...\n  [133 173 221]\n  [128 170 229]\n  [126 168 227]]\n\n ...\n\n [[109 120 109]\n  [109 120 109]\n  [108 119 108]\n  ...\n  [ 61  78  84]\n  [ 61  78  82]\n  [ 60  77  81]]\n\n [[107 118 103]\n  [108 119 104]\n  [108 119 108]\n  ...\n  [ 60  76  87]\n  [ 61  75  85]\n  [ 61  75  85]]\n\n [[105 116 101]\n  [107 118 103]\n  [108 119 108]\n  ...\n  [ 59  75  86]\n  [ 60  74  84]\n  [ 61  75  85]]]\n"
     ]
    }
   ],
   "source": [
    "#Keras helpfully has many built in RNN classifiers; here, we'll focus on the basic implementation of\n",
    "#a simple RNN, which is the same as what we have covered in lecture.\n",
    "#In the case of the simple RNN, each step of the model is fully connected, and the\n",
    "#output from the previous step is fed into the next step.\n",
    "#Keras has a fairly helpful guide on RNNs you can look at here:\n",
    "#https://keras.io/guides/working_with_rnns/\n",
    "\n",
    "#In this analysis, we're going to start analyzing video for the first time.\n",
    "#The full dataset we'll be using is located at:\n",
    "#https://serre-lab.clps.brown.edu/resource/hmdb-a-large-human-motion-database/#overview\n",
    "#But, for this example, we'll just be using a subset of classes:\n",
    "#Cartwheel, Catch, Drink, Hub, Kick, Kiss, Punch and Sit\n",
    "#You will find these movies in the \"HMDB\" folder.\n",
    "\n",
    "#First, we're going to convert our AVI files to frames.  We'll use 10 frames per video for this example.\n",
    "#The package we use to open the video files is called OpenCV, which is a popular video manipulation package.\n",
    "#You will install it with a pip install opencv-python.  We're also going to load in a video display.\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "#==========Visualize in Jupyter: Bonus\n",
    "#Note: this may or may not work, depending on your OS.\n",
    "#If it doesn't work, you're stuck opening the videos in your\n",
    "#media player of choice!  I use VLC.\n",
    "#from IPython.display import Video\n",
    "#Video(\"./HMDB/catch/Frisbee_catch_f_cm_np1_ri_med_0.avi\")\n",
    "#==========\n",
    "\n",
    "#First, we'll extract frames from one video; in the next snippet we'll actually\n",
    "#do this for all cases.  Note we'll only be grabbing 10 frames per video for\n",
    "#the sake of example, equally spaced throughout each clip.\n",
    "\n",
    "frames = []\n",
    "video = cv2.VideoCapture(\"./HMDB/sit/TrumanShow_sit_f_nm_np1_le_med_37.avi\")\n",
    "videoLen = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "print(\"I have \" + str(videoLen) + \" frames.\")\n",
    "\n",
    "#Calculate the gap between frames if we want 10 equally spaced frames.\n",
    "frameGap = math.floor(videoLen/10)\n",
    "print(\"I want to capture every frame starting with 0, incrementing by \" + str(frameGap) + \".\")\n",
    "\n",
    "allFrames = []\n",
    "\n",
    "for frame in range(videoLen):\n",
    "    s, frameData = video.read()\n",
    "    if frame % int(frameGap) == 0:\n",
    "        print(\"I will grab frame \" + str(frame))    \n",
    "        allFrames.append(cv2.cvtColor(frameData, cv2.COLOR_BGR2RGB))\n",
    "\n",
    "#We now have an array for each frame, made up of three layers (RGB) for each video.\n",
    "print(allFrames[0])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now, we're going to do the above procedure, but apply it to every movie\n",
    "#we have, and save the arrays in a new folder for each movie.\n",
    "\n",
    "#First, let's build a short helper function:\n",
    "import pathlib\n",
    "\n",
    "def transformVideo(path, outFolder):\n",
    "    #Make the folder if it doesn't exist already\n",
    "    pathlib.Path(outFolder).mkdir(parents=True, exist_ok=True)\n",
    "    frames = []\n",
    "    video = cv2.VideoCapture(path)\n",
    "    videoLen = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frameGap = math.floor(videoLen/10)\n",
    "    \n",
    "    for frame in range(videoLen):\n",
    "        s, frameData = video.read()\n",
    "        if frame % int(frameGap) == 0:\n",
    "            cv2.imwrite(outFolder + str(frame) + \".jpg\", cv2.cvtColor(frameData, cv2.COLOR_BGR2RGB))\n",
    "    \n",
    "transformVideo(\"./HMDB/sit/TrumanShow_sit_f_nm_np1_le_med_37.avi\", \"./HMDB_frames/sit/1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#And, now, let's apply our transform to all of our videos...\n"
   ]
  }
 ]
}