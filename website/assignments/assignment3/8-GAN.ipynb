{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd08e3a21d38ab9816cf2a4fb5b70910b2de32092d7fedca6365d5651d786256744",
   "display_name": "Python 3.8.5 64-bit ('data442': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "8e3a21d38ab9816cf2a4fb5b70910b2de32092d7fedca6365d5651d786256744"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 352 images belonging to 1 classes.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"250.618594pt\" version=\"1.1\" viewBox=\"0 0 251.565 250.618594\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-12T08:53:07.936988</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 250.618594 \nL 251.565 250.618594 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 226.740469 \nL 244.365 226.740469 \nL 244.365 9.300469 \nL 26.925 9.300469 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#paf5974d5c5)\">\n    <image height=\"218\" id=\"image8810417163\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-8.740469\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m99df57194c\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.62375\" xlink:href=\"#m99df57194c\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(25.4425 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.59875\" xlink:href=\"#m99df57194c\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <g transform=\"translate(56.23625 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"96.57375\" xlink:href=\"#m99df57194c\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20 -->\n      <g transform=\"translate(90.21125 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"130.54875\" xlink:href=\"#m99df57194c\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 30 -->\n      <g transform=\"translate(124.18625 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"164.52375\" xlink:href=\"#m99df57194c\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 40 -->\n      <g transform=\"translate(158.16125 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"198.49875\" xlink:href=\"#m99df57194c\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 50 -->\n      <g transform=\"translate(192.13625 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"232.47375\" xlink:href=\"#m99df57194c\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 60 -->\n      <g transform=\"translate(226.11125 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m96c88a8b20\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m96c88a8b20\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m96c88a8b20\" y=\"44.974219\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 48.773437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m96c88a8b20\" y=\"78.949219\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 82.748437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m96c88a8b20\" y=\"112.924219\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 30 -->\n      <g transform=\"translate(7.2 116.723437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m96c88a8b20\" y=\"146.899219\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 40 -->\n      <g transform=\"translate(7.2 150.698437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m96c88a8b20\" y=\"180.874219\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 50 -->\n      <g transform=\"translate(7.2 184.673437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m96c88a8b20\" y=\"214.849219\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 60 -->\n      <g transform=\"translate(7.2 218.648437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 226.740469 \nL 26.925 9.300469 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 226.740469 \nL 244.365 9.300469 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 226.740469 \nL 244.365 226.740469 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 9.300469 \nL 244.365 9.300469 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"paf5974d5c5\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"9.300469\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "#In this notebook, you'll learn how to implement a Generative Adversarial Network (GAN).\n",
    "#The goal of a GAN is to create one network - a \"Generator\" - which seeks to create pictures\n",
    "#of something (in our case - pokemon); the second network is a \"Discriminator\", which examines\n",
    "#our generated pictures and tries to determine if they are fake or real.\n",
    "#The generator network learns over multiple iterations to \"fool\" the discriminator - \n",
    "#hopefully creating some powerful pokemon!\n",
    "#Note GANs are data hungry, so I'm combining gen1 and gen2 pokemon.  Blasphemy, I know.\n",
    "\n",
    "#(Also Note - Pokemon are a very popular starting point for GAN.  For all sorts of implementations, \n",
    "#search for \"PokeGAN\").\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "#We're going to implement our GAN as a class, mostly so as to keep our sanity!\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.dataFolder = \"./pocketMonsters\"\n",
    "        self.targetShape = (64, 64, 3)\n",
    "        self.batchSize = 64\n",
    "        self.epochs = 100\n",
    "\n",
    "    #Note in our data generator, we're not doing any image augmentation.\n",
    "    #You could, but you would want to limit yourself to generators that\n",
    "    #retain the look, feel, heart and soul of pocketmonsters.\n",
    "    def loadData(self):\n",
    "        dataset_generator = keras.preprocessing.image.ImageDataGenerator().flow_from_directory(\n",
    "            self.dataFolder, target_size=(self.targetShape[0], self.targetShape[1]),\n",
    "            batch_size=self.batchSize,\n",
    "            class_mode=None)\n",
    "\n",
    "        return dataset_generator\n",
    "\n",
    "pokeGAN = GAN()\n",
    "\n",
    "train = pokeGAN.loadData()                                    \n",
    "\n",
    "plt.imshow(next(train)[10].astype('uint8'))\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d (Conv2D)              (None, 32, 32, 64)        4864      \n_________________________________________________________________\nleaky_re_lu (LeakyReLU)      (None, 32, 32, 64)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 16, 16, 128)       204928    \n_________________________________________________________________\nbatch_normalization (BatchNo (None, 16, 16, 128)       512       \n_________________________________________________________________\nleaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 8, 8, 256)         819456    \n_________________________________________________________________\nbatch_normalization_1 (Batch (None, 8, 8, 256)         1024      \n_________________________________________________________________\nleaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 256)         0         \n_________________________________________________________________\nconv2d_3 (Conv2D)            (None, 4, 4, 512)         3277312   \n_________________________________________________________________\nbatch_normalization_2 (Batch (None, 4, 4, 512)         2048      \n_________________________________________________________________\nleaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 512)         0         \n_________________________________________________________________\nflatten (Flatten)            (None, 8192)              0         \n_________________________________________________________________\ndense (Dense)                (None, 1)                 8193      \n_________________________________________________________________\nactivation (Activation)      (None, 1)                 0         \n=================================================================\nTotal params: 4,318,337\nTrainable params: 4,316,545\nNon-trainable params: 1,792\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.dataFolder = \"./pocketMonsters\"\n",
    "        self.targetShape = (64, 64, 3)\n",
    "        self.batchSize = 64\n",
    "        self.epochs = 100\n",
    "\n",
    "    def loadData(self):\n",
    "        dataset_generator = ImageDataGenerator().flow_from_directory(\n",
    "            self.dataFolder, target_size=(self.targetShape[0], self.targetShape[1]),\n",
    "            batch_size=self.batchSize,\n",
    "            class_mode=None)\n",
    "\n",
    "        return dataset_generator\n",
    "\n",
    "    #Next up: our descrimanator!  The basic idea of the GAN is to have a model\n",
    "    #that checks if an image is real, and train another model (the generator)\n",
    "    #on that model.  Here, we're creating the descriminator - i.e., the model\n",
    "    #that checks if something is real or not.\n",
    "    #For now we're just going to define it here - in a few cells, we'll take a look at how\n",
    "    #we train it.\n",
    "    def loadDescriminator(self):\n",
    "        discriminator = keras.models.Sequential()\n",
    "        discriminator.add(keras.layers.Conv2D(filters=64, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform',\n",
    "                                    input_shape=self.targetShape))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Conv2D(filters=128, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "        discriminator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Conv2D(filters=256, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "        discriminator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Conv2D(filters=512, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "        discriminator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Flatten())\n",
    "        discriminator.add(keras.layers.Dense(1))\n",
    "        discriminator.add(keras.layers.Activation('sigmoid'))\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "        discriminator.compile(loss='binary_crossentropy',\n",
    "                                optimizer=optimizer,\n",
    "                                metrics=None)\n",
    "\n",
    "        return discriminator\n",
    "\n",
    "pokeGAN = GAN()\n",
    "\n",
    "model = pokeGAN.loadDescriminator() \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_1 (Dense)              (None, 1, 1, 8192)        827392    \n_________________________________________________________________\nreshape (Reshape)            (None, 4, 4, 512)         0         \n_________________________________________________________________\nbatch_normalization_3 (Batch (None, 4, 4, 512)         2048      \n_________________________________________________________________\nactivation_1 (Activation)    (None, 4, 4, 512)         0         \n_________________________________________________________________\nconv2d_transpose (Conv2DTran (None, 8, 8, 256)         3277056   \n_________________________________________________________________\nbatch_normalization_4 (Batch (None, 8, 8, 256)         1024      \n_________________________________________________________________\nactivation_2 (Activation)    (None, 8, 8, 256)         0         \n_________________________________________________________________\nconv2d_transpose_1 (Conv2DTr (None, 16, 16, 128)       819328    \n_________________________________________________________________\nbatch_normalization_5 (Batch (None, 16, 16, 128)       512       \n_________________________________________________________________\nactivation_3 (Activation)    (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d_transpose_2 (Conv2DTr (None, 32, 32, 64)        204864    \n_________________________________________________________________\nbatch_normalization_6 (Batch (None, 32, 32, 64)        256       \n_________________________________________________________________\nactivation_4 (Activation)    (None, 32, 32, 64)        0         \n_________________________________________________________________\nconv2d_transpose_3 (Conv2DTr (None, 64, 64, 3)         4803      \n_________________________________________________________________\nactivation_5 (Activation)    (None, 64, 64, 3)         0         \n=================================================================\nTotal params: 5,137,283\nTrainable params: 5,135,363\nNon-trainable params: 1,920\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.dataFolder = \"./pocketMonsters\"\n",
    "        self.targetShape = (64, 64, 3)\n",
    "        self.batchSize = 64\n",
    "        self.epochs = 100\n",
    "\n",
    "    #And, here is our generator.  This is a model that attempts\n",
    "    #to create images that will fool the discriminator.\n",
    "    #Again, we'll use this in a few cells to show how it works.\n",
    "    #Of note is the input_shape for the first dense layer -\n",
    "    #this is going to represent an input of random noise\n",
    "    #that we're using to initialize the generator.\n",
    "    def loadGenerator(self):\n",
    "        generator = keras.models.Sequential()\n",
    "        generator.add(keras.layers.Dense(units=4 * 4 * 512,\n",
    "                            kernel_initializer='glorot_uniform',\n",
    "                            input_shape=(1, 1, 100)))\n",
    "        generator.add(keras.layers.Reshape(target_shape=(4, 4, 512)))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.Activation('tanh'))\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=0.00015, beta_1=0.5)\n",
    "        generator.compile(loss='binary_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=None)\n",
    "\n",
    "        return generator\n",
    "\n",
    "pokeGAN = GAN()\n",
    "\n",
    "model = pokeGAN.loadGenerator() \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.dataFolder = \"./pocketMonsters\"\n",
    "        self.targetShape = (64, 64, 3)\n",
    "        self.batchSize = 64\n",
    "        self.epochs = 100\n",
    "\n",
    "    #Next up is a small helper function so we can see how the images evolve\n",
    "    #across epochs:\n",
    "    def saveImages(self, genImage, epochNum, batchNum):\n",
    "            #We're generating 64 pokemon each iteration:\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            grid = gridspec.GridSpec(8, 8)\n",
    "            grid.update(wspace=0.1, hspace=0.1)\n",
    "\n",
    "            for i in range(64):\n",
    "                ax1 = plt.subplot(grid[i])\n",
    "                ax1.set_aspect('equal')\n",
    "                image = generated_images[i, :, :, :]\n",
    "\n",
    "                #Scale colors between 1 and 255\n",
    "                image += 1\n",
    "                image *= 255\n",
    "                fig = plt.imshow(image.astype(np.uint8))\n",
    "                plt.axis('off')\n",
    "                fig.axes.get_xaxis().set_visible(False)\n",
    "                fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            save_name = 'myPokemon/epoch' + str(epoch_no + 1) + 'Batch' + str(batch_no + 1) + '.png'\n",
    "            if not os.path.exists('myPokemon'):\n",
    "                os.mkdir('myPokemon')\n",
    "            plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.dataFolder = \"./pocketMonsters\"\n",
    "        self.targetShape = (64, 64, 3)\n",
    "        self.batchSize = 64\n",
    "        self.epochs = 100\n",
    "\n",
    "    #Now we need to define how the generator and dicriminator\n",
    "    #will interact, and how we'll optimize them.  This is \n",
    "    #the GAN itself.\n",
    "    def loadGAN(self, generator, discriminator):\n",
    "        m = keras.models.Sequential()\n",
    "        discriminator.trainable = False\n",
    "        m.add(generator)\n",
    "        m.add(discriminator)\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=0.00015, beta_1=0.5)\n",
    "        m.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                    metrics=None)\n",
    "        return m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "Epoch179 Batch 1 of 13 | Generator Loss: 0.34 | Discriminator Loss: 0.662 | Time: 0.28298401832580566 seconds.\n",
      "Epoch179 Batch 2 of 13 | Generator Loss: 0.327 | Discriminator Loss: 0.634 | Time: 0.29552340507507324 seconds.\n",
      "Epoch179 Batch 3 of 13 | Generator Loss: 0.312 | Discriminator Loss: 0.635 | Time: 0.28867006301879883 seconds.\n",
      "Epoch179 Batch 4 of 13 | Generator Loss: 0.325 | Discriminator Loss: 0.626 | Time: 0.29152703285217285 seconds.\n",
      "Epoch179 Batch 5 of 13 | Generator Loss: 0.321 | Discriminator Loss: 0.688 | Time: 0.3036825656890869 seconds.\n",
      "Epoch179 Batch 6 of 13 | Generator Loss: 0.359 | Discriminator Loss: 0.66 | Time: 0.29406070709228516 seconds.\n",
      "Epoch179 Batch 7 of 13 | Generator Loss: 0.335 | Discriminator Loss: 0.687 | Time: 0.31173181533813477 seconds.\n",
      "Epoch179 Batch 8 of 13 | Generator Loss: 0.341 | Discriminator Loss: 0.662 | Time: 0.2917745113372803 seconds.\n",
      "Epoch179 Batch 9 of 13 | Generator Loss: 0.292 | Discriminator Loss: 0.705 | Time: 0.294466495513916 seconds.\n",
      "Epoch179 Batch 10 of 13 | Generator Loss: 0.337 | Discriminator Loss: 0.722 | Time: 0.2988131046295166 seconds.\n",
      "Epoch179 Batch 11 of 13 | Generator Loss: 0.32 | Discriminator Loss: 0.69 | Time: 0.2835817337036133 seconds.\n",
      "Epoch179 Batch 12 of 13 | Generator Loss: 0.325 | Discriminator Loss: 0.739 | Time: 0.32015395164489746 seconds.\n",
      "Epoch179 Batch 13 of 13 | Generator Loss: 0.314 | Discriminator Loss: 0.717 | Time: 0.26670122146606445 seconds.\n",
      "Epoch: 181 of 1000\n",
      "Epoch180 Batch 1 of 13 | Generator Loss: 0.328 | Discriminator Loss: 0.645 | Time: 0.2600979804992676 seconds.\n",
      "Epoch180 Batch 2 of 13 | Generator Loss: 0.354 | Discriminator Loss: 0.686 | Time: 0.29704976081848145 seconds.\n",
      "Epoch180 Batch 3 of 13 | Generator Loss: 0.324 | Discriminator Loss: 0.652 | Time: 0.2968254089355469 seconds.\n",
      "Epoch180 Batch 4 of 13 | Generator Loss: 0.341 | Discriminator Loss: 0.675 | Time: 0.2945575714111328 seconds.\n",
      "Epoch180 Batch 5 of 13 | Generator Loss: 0.325 | Discriminator Loss: 0.674 | Time: 0.2954671382904053 seconds.\n",
      "Epoch180 Batch 6 of 13 | Generator Loss: 0.331 | Discriminator Loss: 0.618 | Time: 0.292492151260376 seconds.\n",
      "Epoch180 Batch 7 of 13 | Generator Loss: 0.359 | Discriminator Loss: 0.688 | Time: 0.30408191680908203 seconds.\n",
      "Epoch180 Batch 8 of 13 | Generator Loss: 0.345 | Discriminator Loss: 0.663 | Time: 0.2918868064880371 seconds.\n",
      "Epoch180 Batch 9 of 13 | Generator Loss: 0.314 | Discriminator Loss: 0.647 | Time: 0.2997252941131592 seconds.\n",
      "Epoch180 Batch 10 of 13 | Generator Loss: 0.304 | Discriminator Loss: 0.679 | Time: 0.27229905128479004 seconds.\n",
      "Epoch180 Batch 11 of 13 | Generator Loss: 0.338 | Discriminator Loss: 0.667 | Time: 0.3079690933227539 seconds.\n",
      "Epoch180 Batch 12 of 13 | Generator Loss: 0.32 | Discriminator Loss: 0.659 | Time: 0.28229355812072754 seconds.\n",
      "Epoch180 Batch 13 of 13 | Generator Loss: 0.334 | Discriminator Loss: 0.654 | Time: 0.29281044006347656 seconds.\n",
      "Epoch: 182 of 1000\n",
      "Epoch181 Batch 1 of 13 | Generator Loss: 0.319 | Discriminator Loss: 0.641 | Time: 0.2676820755004883 seconds.\n",
      "Epoch181 Batch 2 of 13 | Generator Loss: 0.31 | Discriminator Loss: 0.671 | Time: 0.2977602481842041 seconds.\n",
      "Epoch181 Batch 3 of 13 | Generator Loss: 0.314 | Discriminator Loss: 0.653 | Time: 0.2969999313354492 seconds.\n",
      "Epoch181 Batch 4 of 13 | Generator Loss: 0.311 | Discriminator Loss: 0.635 | Time: 0.29340267181396484 seconds.\n",
      "Epoch181 Batch 5 of 13 | Generator Loss: 0.324 | Discriminator Loss: 0.647 | Time: 0.2923924922943115 seconds.\n",
      "Epoch181 Batch 6 of 13 | Generator Loss: 0.337 | Discriminator Loss: 0.67 | Time: 0.29859089851379395 seconds.\n",
      "Epoch181 Batch 7 of 13 | Generator Loss: 0.325 | Discriminator Loss: 0.648 | Time: 0.3162069320678711 seconds.\n",
      "Epoch181 Batch 8 of 13 | Generator Loss: 0.333 | Discriminator Loss: 0.657 | Time: 0.2832450866699219 seconds.\n",
      "Epoch181 Batch 9 of 13 | Generator Loss: 0.311 | Discriminator Loss: 0.604 | Time: 0.28023290634155273 seconds.\n",
      "Epoch181 Batch 10 of 13 | Generator Loss: 0.336 | Discriminator Loss: 0.639 | Time: 0.2878246307373047 seconds.\n",
      "Epoch181 Batch 11 of 13 | Generator Loss: 0.338 | Discriminator Loss: 0.664 | Time: 0.2889738082885742 seconds.\n",
      "Epoch181 Batch 12 of 13 | Generator Loss: 0.345 | Discriminator Loss: 0.638 | Time: 0.2931642532348633 seconds.\n",
      "Epoch181 Batch 13 of 13 | Generator Loss: 0.314 | Discriminator Loss: 0.631 | Time: 0.26427769660949707 seconds.\n",
      "Epoch: 183 of 1000\n",
      "Epoch182 Batch 1 of 13 | Generator Loss: 0.322 | Discriminator Loss: 0.667 | Time: 0.28261256217956543 seconds.\n",
      "Epoch182 Batch 2 of 13 | Generator Loss: 0.328 | Discriminator Loss: 0.656 | Time: 0.2853407859802246 seconds.\n",
      "Epoch182 Batch 3 of 13 | Generator Loss: 0.326 | Discriminator Loss: 0.632 | Time: 0.3047146797180176 seconds.\n",
      "Epoch182 Batch 4 of 13 | Generator Loss: 0.32 | Discriminator Loss: 0.628 | Time: 0.2906002998352051 seconds.\n",
      "Epoch182 Batch 5 of 13 | Generator Loss: 0.356 | Discriminator Loss: 0.683 | Time: 0.2963273525238037 seconds.\n",
      "Epoch182 Batch 6 of 13 | Generator Loss: 0.328 | Discriminator Loss: 0.652 | Time: 0.28487586975097656 seconds.\n",
      "Epoch182 Batch 7 of 13 | Generator Loss: 0.325 | Discriminator Loss: 0.668 | Time: 0.3122830390930176 seconds.\n",
      "Epoch182 Batch 8 of 13 | Generator Loss: 0.329 | Discriminator Loss: 0.679 | Time: 0.2907724380493164 seconds.\n",
      "Epoch182 Batch 9 of 13 | Generator Loss: 0.323 | Discriminator Loss: 0.623 | Time: 0.3028552532196045 seconds.\n",
      "Epoch182 Batch 10 of 13 | Generator Loss: 0.325 | Discriminator Loss: 0.712 | Time: 0.29463934898376465 seconds.\n",
      "Epoch182 Batch 11 of 13 | Generator Loss: 0.357 | Discriminator Loss: 0.684 | Time: 0.31819772720336914 seconds.\n",
      "Epoch182 Batch 12 of 13 | Generator Loss: 0.322 | Discriminator Loss: 0.672 | Time: 0.29569530487060547 seconds.\n",
      "Epoch182 Batch 13 of 13 | Generator Loss: 0.321 | Discriminator Loss: 0.625 | Time: 0.2905864715576172 seconds.\n",
      "Epoch: 184 of 1000\n",
      "Epoch183 Batch 1 of 13 | Generator Loss: 0.321 | Discriminator Loss: 0.73 | Time: 0.261371374130249 seconds.\n",
      "Epoch183 Batch 2 of 13 | Generator Loss: 0.313 | Discriminator Loss: 0.64 | Time: 0.2824134826660156 seconds.\n",
      "Epoch183 Batch 3 of 13 | Generator Loss: 0.339 | Discriminator Loss: 0.712 | Time: 0.291485071182251 seconds.\n",
      "Epoch183 Batch 4 of 13 | Generator Loss: 0.418 | Discriminator Loss: 0.696 | Time: 0.29078030586242676 seconds.\n",
      "Epoch183 Batch 5 of 13 | Generator Loss: 0.314 | Discriminator Loss: 0.841 | Time: 0.29213929176330566 seconds.\n",
      "Epoch183 Batch 6 of 13 | Generator Loss: 0.339 | Discriminator Loss: 0.697 | Time: 0.29251694679260254 seconds.\n",
      "Epoch183 Batch 7 of 13 | Generator Loss: 0.324 | Discriminator Loss: 0.678 | Time: 0.28731632232666016 seconds.\n",
      "Epoch183 Batch 8 of 13 | Generator Loss: 0.344 | Discriminator Loss: 0.67 | Time: 0.29062891006469727 seconds.\n",
      "Epoch183 Batch 9 of 13 | Generator Loss: 0.329 | Discriminator Loss: 0.676 | Time: 0.2777557373046875 seconds.\n",
      "Epoch183 Batch 10 of 13 | Generator Loss: 0.333 | Discriminator Loss: 0.651 | Time: 0.29186034202575684 seconds.\n",
      "Epoch183 Batch 11 of 13 | Generator Loss: 0.319 | Discriminator Loss: 0.604 | Time: 0.27977848052978516 seconds.\n",
      "Epoch183 Batch 12 of 13 | Generator Loss: 0.336 | Discriminator Loss: 0.651 | Time: 0.2846791744232178 seconds.\n",
      "Epoch183 Batch 13 of 13 | Generator Loss: 0.332 | Discriminator Loss: 0.635 | Time: 0.2859821319580078 seconds.\n",
      "Epoch: 185 of 1000\n",
      "Epoch184 Batch 1 of 13 | Generator Loss: 0.325 | Discriminator Loss: 0.631 | Time: 0.26926207542419434 seconds.\n",
      "Epoch184 Batch 2 of 13 | Generator Loss: 0.375 | Discriminator Loss: 0.644 | Time: 0.2963235378265381 seconds.\n",
      "Epoch184 Batch 3 of 13 | Generator Loss: 0.348 | Discriminator Loss: 0.666 | Time: 0.28224730491638184 seconds.\n",
      "Epoch184 Batch 4 of 13 | Generator Loss: 0.327 | Discriminator Loss: 0.638 | Time: 0.2962484359741211 seconds.\n",
      "Epoch184 Batch 5 of 13 | Generator Loss: 0.337 | Discriminator Loss: 0.645 | Time: 0.29306650161743164 seconds.\n",
      "Epoch184 Batch 6 of 13 | Generator Loss: 0.341 | Discriminator Loss: 0.65 | Time: 0.2946739196777344 seconds.\n",
      "Epoch184 Batch 7 of 13 | Generator Loss: 0.342 | Discriminator Loss: 0.671 | Time: 0.30371594429016113 seconds.\n",
      "Epoch184 Batch 8 of 13 | Generator Loss: 0.321 | Discriminator Loss: 0.656 | Time: 0.30406951904296875 seconds.\n",
      "Epoch184 Batch 9 of 13 | Generator Loss: 0.326 | Discriminator Loss: 0.622 | Time: 0.2915060520172119 seconds.\n",
      "Epoch184 Batch 10 of 13 | Generator Loss: 0.339 | Discriminator Loss: 0.647 | Time: 0.28937387466430664 seconds.\n",
      "Epoch184 Batch 11 of 13 | Generator Loss: 0.322 | Discriminator Loss: 0.632 | Time: 0.29547953605651855 seconds.\n",
      "Epoch184 Batch 12 of 13 | Generator Loss: 0.317 | Discriminator Loss: 0.656 | Time: 0.32006311416625977 seconds.\n",
      "Epoch184 Batch 13 of 13 | Generator Loss: 0.341 | Discriminator Loss: 0.655 | Time: 0.296985387802124 seconds.\n",
      "Epoch: 186 of 1000\n",
      "Epoch185 Batch 1 of 13 | Generator Loss: 0.325 | Discriminator Loss: 0.655 | Time: 0.27943968772888184 seconds.\n",
      "Epoch185 Batch 2 of 13 | Generator Loss: 0.364 | Discriminator Loss: 0.668 | Time: 0.31203222274780273 seconds.\n",
      "Epoch185 Batch 3 of 13 | Generator Loss: 0.321 | Discriminator Loss: 0.648 | Time: 0.29078245162963867 seconds.\n",
      "Epoch185 Batch 4 of 13 | Generator Loss: 0.337 | Discriminator Loss: 0.645 | Time: 0.29537343978881836 seconds.\n",
      "Epoch185 Batch 5 of 13 | Generator Loss: 0.316 | Discriminator Loss: 0.661 | Time: 0.28641557693481445 seconds.\n",
      "Epoch185 Batch 6 of 13 | Generator Loss: 0.332 | Discriminator Loss: 0.664 | Time: 0.2830653190612793 seconds.\n",
      "Epoch185 Batch 7 of 13 | Generator Loss: 0.341 | Discriminator Loss: 0.631 | Time: 0.3145415782928467 seconds.\n",
      "Epoch185 Batch 8 of 13 | Generator Loss: 0.321 | Discriminator Loss: 0.647 | Time: 0.271334171295166 seconds.\n",
      "Epoch185 Batch 9 of 13 | Generator Loss: 0.356 | Discriminator Loss: 0.65 | Time: 0.3069455623626709 seconds.\n",
      "Epoch185 Batch 10 of 13 | Generator Loss: 0.352 | Discriminator Loss: 0.666 | Time: 0.29409360885620117 seconds.\n",
      "Epoch185 Batch 11 of 13 | Generator Loss: 0.333 | Discriminator Loss: 0.668 | Time: 0.29700469970703125 seconds.\n",
      "Epoch185 Batch 12 of 13 | Generator Loss: 0.311 | Discriminator Loss: 0.679 | Time: 0.3043210506439209 seconds.\n",
      "Epoch185 Batch 13 of 13 | Generator Loss: 0.328 | Discriminator Loss: 0.656 | Time: 0.28214073181152344 seconds.\n",
      "Epoch: 187 of 1000\n",
      "Epoch186 Batch 1 of 13 | Generator Loss: 0.338 | Discriminator Loss: 0.652 | Time: 0.2738182544708252 seconds.\n",
      "Epoch186 Batch 2 of 13 | Generator Loss: 0.335 | Discriminator Loss: 0.72 | Time: 0.3172295093536377 seconds.\n",
      "Epoch186 Batch 3 of 13 | Generator Loss: 0.355 | Discriminator Loss: 0.699 | Time: 0.3159763813018799 seconds.\n",
      "Epoch186 Batch 4 of 13 | Generator Loss: 0.333 | Discriminator Loss: 0.714 | Time: 0.3094325065612793 seconds.\n",
      "Epoch186 Batch 5 of 13 | Generator Loss: 0.38 | Discriminator Loss: 0.671 | Time: 0.3004157543182373 seconds.\n",
      "Epoch186 Batch 6 of 13 | Generator Loss: 0.369 | Discriminator Loss: 0.788 | Time: 0.30365562438964844 seconds.\n",
      "Epoch186 Batch 7 of 13 | Generator Loss: 0.423 | Discriminator Loss: 0.685 | Time: 0.3058478832244873 seconds.\n",
      "Epoch186 Batch 8 of 13 | Generator Loss: 0.397 | Discriminator Loss: 0.668 | Time: 0.30171847343444824 seconds.\n",
      "Epoch186 Batch 9 of 13 | Generator Loss: 0.379 | Discriminator Loss: 0.684 | Time: 0.32531309127807617 seconds.\n",
      "Epoch186 Batch 10 of 13 | Generator Loss: 0.452 | Discriminator Loss: 0.634 | Time: 0.31043577194213867 seconds.\n",
      "Epoch186 Batch 11 of 13 | Generator Loss: 0.373 | Discriminator Loss: 0.761 | Time: 0.3086974620819092 seconds.\n",
      "Epoch186 Batch 12 of 13 | Generator Loss: 0.481 | Discriminator Loss: 0.706 | Time: 0.30031824111938477 seconds.\n",
      "Epoch186 Batch 13 of 13 | Generator Loss: 0.413 | Discriminator Loss: 0.746 | Time: 0.2793731689453125 seconds.\n",
      "Epoch: 188 of 1000\n",
      "Epoch187 Batch 1 of 13 | Generator Loss: 0.33 | Discriminator Loss: 0.701 | Time: 0.27396106719970703 seconds.\n",
      "Epoch187 Batch 2 of 13 | Generator Loss: 0.427 | Discriminator Loss: 0.692 | Time: 0.34157252311706543 seconds.\n",
      "Epoch187 Batch 3 of 13 | Generator Loss: 0.363 | Discriminator Loss: 0.75 | Time: 0.2911052703857422 seconds.\n",
      "Epoch187 Batch 4 of 13 | Generator Loss: 0.365 | Discriminator Loss: 0.695 | Time: 0.29996633529663086 seconds.\n",
      "Epoch187 Batch 5 of 13 | Generator Loss: 0.308 | Discriminator Loss: 0.754 | Time: 0.2986621856689453 seconds.\n",
      "Epoch187 Batch 6 of 13 | Generator Loss: 0.384 | Discriminator Loss: 0.65 | Time: 0.27819347381591797 seconds.\n",
      "Epoch187 Batch 7 of 13 | Generator Loss: 0.329 | Discriminator Loss: 0.641 | Time: 0.30094480514526367 seconds.\n",
      "Epoch187 Batch 8 of 13 | Generator Loss: 0.336 | Discriminator Loss: 0.699 | Time: 0.29532670974731445 seconds.\n",
      "Epoch187 Batch 9 of 13 | Generator Loss: 0.349 | Discriminator Loss: 0.69 | Time: 0.29498910903930664 seconds.\n",
      "Epoch187 Batch 10 of 13 | Generator Loss: 0.378 | Discriminator Loss: 0.674 | Time: 0.30408406257629395 seconds.\n",
      "Epoch187 Batch 11 of 13 | Generator Loss: 0.389 | Discriminator Loss: 0.656 | Time: 0.2886199951171875 seconds.\n",
      "Epoch187 Batch 12 of 13 | Generator Loss: 0.327 | Discriminator Loss: 0.686 | Time: 0.31255578994750977 seconds.\n",
      "Epoch187 Batch 13 of 13 | Generator Loss: 0.302 | Discriminator Loss: 0.693 | Time: 0.3120143413543701 seconds.\n",
      "Epoch: 189 of 1000\n",
      "Epoch188 Batch 1 of 13 | Generator Loss: 0.37 | Discriminator Loss: 0.701 | Time: 0.2850053310394287 seconds.\n",
      "Epoch188 Batch 2 of 13 | Generator Loss: 0.359 | Discriminator Loss: 0.676 | Time: 0.2993597984313965 seconds.\n",
      "Epoch188 Batch 3 of 13 | Generator Loss: 0.35 | Discriminator Loss: 0.689 | Time: 0.29166603088378906 seconds.\n",
      "Epoch188 Batch 4 of 13 | Generator Loss: 0.326 | Discriminator Loss: 0.72 | Time: 0.29134035110473633 seconds.\n",
      "Epoch188 Batch 5 of 13 | Generator Loss: 0.333 | Discriminator Loss: 0.664 | Time: 0.30511474609375 seconds.\n",
      "Epoch188 Batch 6 of 13 | Generator Loss: 0.361 | Discriminator Loss: 0.747 | Time: 0.3121650218963623 seconds.\n",
      "Epoch188 Batch 7 of 13 | Generator Loss: 0.385 | Discriminator Loss: 0.728 | Time: 0.29628705978393555 seconds.\n",
      "Epoch188 Batch 8 of 13 | Generator Loss: 0.334 | Discriminator Loss: 0.699 | Time: 0.3032684326171875 seconds.\n",
      "Epoch188 Batch 9 of 13 | Generator Loss: 0.323 | Discriminator Loss: 0.694 | Time: 0.3061220645904541 seconds.\n",
      "Epoch188 Batch 10 of 13 | Generator Loss: 0.347 | Discriminator Loss: 0.655 | Time: 0.29430556297302246 seconds.\n",
      "Epoch188 Batch 11 of 13 | Generator Loss: 0.349 | Discriminator Loss: 0.654 | Time: 0.3128218650817871 seconds.\n",
      "Epoch188 Batch 12 of 13 | Generator Loss: 0.342 | Discriminator Loss: 0.646 | Time: 0.2897300720214844 seconds.\n",
      "Epoch188 Batch 13 of 13 | Generator Loss: 0.335 | Discriminator Loss: 0.686 | Time: 0.26879382133483887 seconds.\n",
      "Epoch: 190 of 1000\n",
      "Epoch189 Batch 1 of 13 | Generator Loss: 0.369 | Discriminator Loss: 0.646 | Time: 0.2777292728424072 seconds.\n",
      "Epoch189 Batch 2 of 13 | Generator Loss: 0.336 | Discriminator Loss: 0.675 | Time: 0.30225229263305664 seconds.\n",
      "Epoch189 Batch 3 of 13 | Generator Loss: 0.356 | Discriminator Loss: 0.68 | Time: 0.3117098808288574 seconds.\n",
      "Epoch189 Batch 4 of 13 | Generator Loss: 0.34 | Discriminator Loss: 0.675 | Time: 0.3121755123138428 seconds.\n",
      "Epoch189 Batch 5 of 13 | Generator Loss: 0.368 | Discriminator Loss: 0.656 | Time: 0.2998926639556885 seconds.\n",
      "Epoch189 Batch 6 of 13 | Generator Loss: 0.347 | Discriminator Loss: 0.647 | Time: 0.29191017150878906 seconds.\n",
      "Epoch189 Batch 7 of 13 | Generator Loss: 0.314 | Discriminator Loss: 0.659 | Time: 0.2847170829772949 seconds.\n",
      "Epoch189 Batch 8 of 13 | Generator Loss: 0.364 | Discriminator Loss: 0.642 | Time: 0.31302332878112793 seconds.\n",
      "Epoch189 Batch 9 of 13 | Generator Loss: 0.336 | Discriminator Loss: 0.691 | Time: 0.29764509201049805 seconds.\n",
      "Epoch189 Batch 10 of 13 | Generator Loss: 0.319 | Discriminator Loss: 0.661 | Time: 0.30536651611328125 seconds.\n",
      "Epoch189 Batch 11 of 13 | Generator Loss: 0.335 | Discriminator Loss: 0.638 | Time: 0.30205655097961426 seconds.\n",
      "Epoch189 Batch 12 of 13 | Generator Loss: 0.346 | Discriminator Loss: 0.667 | Time: 0.33016467094421387 seconds.\n",
      "Epoch189 Batch 13 of 13 | Generator Loss: 0.331 | Discriminator Loss: 0.684 | Time: 0.29405999183654785 seconds.\n",
      "Epoch: 191 of 1000\n",
      "Epoch190 Batch 1 of 13 | Generator Loss: 0.333 | Discriminator Loss: 0.665 | Time: 0.291534423828125 seconds.\n",
      "Epoch190 Batch 2 of 13 | Generator Loss: 0.349 | Discriminator Loss: 0.712 | Time: 0.3109250068664551 seconds.\n",
      "Epoch190 Batch 3 of 13 | Generator Loss: 0.331 | Discriminator Loss: 0.623 | Time: 0.30428218841552734 seconds.\n",
      "Epoch190 Batch 4 of 13 | Generator Loss: 0.345 | Discriminator Loss: 0.633 | Time: 0.2831289768218994 seconds.\n",
      "Epoch190 Batch 5 of 13 | Generator Loss: 0.33 | Discriminator Loss: 0.652 | Time: 0.29419827461242676 seconds.\n",
      "Epoch190 Batch 6 of 13 | Generator Loss: 0.334 | Discriminator Loss: 0.641 | Time: 0.30097341537475586 seconds.\n",
      "Epoch190 Batch 7 of 13 | Generator Loss: 0.345 | Discriminator Loss: 0.664 | Time: 0.30080223083496094 seconds.\n",
      "Epoch190 Batch 8 of 13 | Generator Loss: 0.32 | Discriminator Loss: 0.666 | Time: 0.30309438705444336 seconds.\n",
      "Epoch190 Batch 9 of 13 | Generator Loss: 0.338 | Discriminator Loss: 0.65 | Time: 0.3119792938232422 seconds.\n",
      "Epoch190 Batch 10 of 13 | Generator Loss: 0.332 | Discriminator Loss: 0.669 | Time: 0.3174874782562256 seconds.\n",
      "Epoch190 Batch 11 of 13 | Generator Loss: 0.335 | Discriminator Loss: 0.659 | Time: 0.3198280334472656 seconds.\n",
      "Epoch190 Batch 12 of 13 | Generator Loss: 0.317 | Discriminator Loss: 0.609 | Time: 0.30768823623657227 seconds.\n",
      "Epoch190 Batch 13 of 13 | Generator Loss: 0.313 | Discriminator Loss: 0.676 | Time: 0.29075050354003906 seconds.\n",
      "Epoch: 192 of 1000\n",
      "Epoch191 Batch 1 of 13 | Generator Loss: 0.357 | Discriminator Loss: 0.695 | Time: 0.2781944274902344 seconds.\n",
      "Epoch191 Batch 2 of 13 | Generator Loss: 0.334 | Discriminator Loss: 0.644 | Time: 0.31931161880493164 seconds.\n",
      "Epoch191 Batch 3 of 13 | Generator Loss: 0.323 | Discriminator Loss: 0.67 | Time: 0.295011043548584 seconds.\n",
      "Epoch191 Batch 4 of 13 | Generator Loss: 0.354 | Discriminator Loss: 0.651 | Time: 0.31661462783813477 seconds.\n",
      "Epoch191 Batch 5 of 13 | Generator Loss: 0.306 | Discriminator Loss: 0.627 | Time: 0.31720829010009766 seconds.\n",
      "Epoch191 Batch 6 of 13 | Generator Loss: 0.326 | Discriminator Loss: 0.662 | Time: 0.30414271354675293 seconds.\n",
      "Epoch191 Batch 7 of 13 | Generator Loss: 0.327 | Discriminator Loss: 0.673 | Time: 0.31727099418640137 seconds.\n",
      "Epoch191 Batch 8 of 13 | Generator Loss: 0.342 | Discriminator Loss: 0.693 | Time: 0.3128080368041992 seconds.\n",
      "Epoch191 Batch 9 of 13 | Generator Loss: 0.353 | Discriminator Loss: 0.693 | Time: 0.30361151695251465 seconds.\n",
      "Epoch191 Batch 10 of 13 | Generator Loss: 0.318 | Discriminator Loss: 0.665 | Time: 0.30671024322509766 seconds.\n",
      "Epoch191 Batch 11 of 13 | Generator Loss: 0.326 | Discriminator Loss: 0.642 | Time: 0.31380319595336914 seconds.\n",
      "Epoch191 Batch 12 of 13 | Generator Loss: 0.346 | Discriminator Loss: 0.637 | Time: 0.33472537994384766 seconds.\n",
      "Epoch191 Batch 13 of 13 | Generator Loss: 0.342 | Discriminator Loss: 0.618 | Time: 0.29624056816101074 seconds.\n",
      "Epoch: 193 of 1000\n",
      "Epoch192 Batch 1 of 13 | Generator Loss: 0.33 | Discriminator Loss: 0.659 | Time: 0.29140353202819824 seconds.\n",
      "Epoch192 Batch 2 of 13 | Generator Loss: 0.341 | Discriminator Loss: 0.7 | Time: 0.29665088653564453 seconds.\n",
      "Epoch192 Batch 3 of 13 | Generator Loss: 0.322 | Discriminator Loss: 0.655 | Time: 0.3007791042327881 seconds.\n",
      "Epoch192 Batch 4 of 13 | Generator Loss: 0.336 | Discriminator Loss: 0.715 | Time: 0.3105766773223877 seconds.\n",
      "Epoch192 Batch 5 of 13 | Generator Loss: 0.342 | Discriminator Loss: 0.662 | Time: 0.32953381538391113 seconds.\n",
      "Epoch192 Batch 6 of 13 | Generator Loss: 0.338 | Discriminator Loss: 0.677 | Time: 0.31103062629699707 seconds.\n",
      "Epoch192 Batch 7 of 13 | Generator Loss: 0.353 | Discriminator Loss: 0.672 | Time: 0.32369041442871094 seconds.\n",
      "Epoch192 Batch 8 of 13 | Generator Loss: 0.35 | Discriminator Loss: 0.736 | Time: 0.3103749752044678 seconds.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-fe2f084c2e2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    284\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[0mmakePokemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m \u001b[0mmakePokemon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-20-fe2f084c2e2d>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;31m#the discriminator training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0mdiscLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrealPokemonImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrealPokemon_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m                 \u001b[0mdiscLoss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mdiscriminator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfakePokemonImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfakePokemon_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0mdiscriminatorLoss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdiscriminatorLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscLoss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1721\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1722\u001b[0m          \u001b[0mtraining_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRespectCompiledTrainableState\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1723\u001b[0;31m       iterator = data_adapter.single_batch_iterator(self.distribute_strategy, x,\n\u001b[0m\u001b[1;32m   1724\u001b[0m                                                     \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1725\u001b[0m                                                     class_weight)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36msingle_batch_iterator\u001b[0;34m(strategy, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_make_class_weight_map_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m   \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstrategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_distribute_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    420\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minside_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 422\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    423\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    424\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    680\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcomponents\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0melement_spec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    683\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    684\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    685\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 686\u001b[0;31m     \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply_options\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    687\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m     \u001b[0;31m# Store dataset reference to ensure that dataset is alive when this iterator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m_apply_options\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    395\u001b[0m           (options.experimental_optimization.apply_default_optimizations  # pylint: disable=g-bool-id-comparison\n\u001b[1;32m    396\u001b[0m            is not False)):\n\u001b[0;32m--> 397\u001b[0;31m       dataset = _OptimizeDataset(dataset, graph_rewrites.enabled,\n\u001b[0m\u001b[1;32m    398\u001b[0m                                  \u001b[0mgraph_rewrites\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisabled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m                                  graph_rewrites.default, graph_rewrite_configs)\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, optimizations_enabled, optimizations_disabled, optimizations_default, optimization_configs)\u001b[0m\n\u001b[1;32m   4575\u001b[0m         argument_dtype=dtypes.string)\n\u001b[1;32m   4576\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4577\u001b[0;31m     variant_tensor = gen_dataset_ops.optimize_dataset_v2(\n\u001b[0m\u001b[1;32m   4578\u001b[0m         \u001b[0minput_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variant_tensor\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4579\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizations_enabled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36moptimize_dataset_v2\u001b[0;34m(input_dataset, optimizations_enabled, optimizations_disabled, optimizations_default, output_types, output_shapes, optimization_configs, name)\u001b[0m\n\u001b[1;32m   4019\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4020\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4021\u001b[0;31m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[1;32m   4022\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"OptimizeDatasetV2\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizations_enabled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4023\u001b[0m         \u001b[0moptimizations_disabled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizations_default\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"output_types\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Finally, we add everything together into a mega-Class.\n",
    "#The real heavy lifting is in the final method here - our training method!\n",
    "#Running this cell will build our GAN.\n",
    "\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import keras\n",
    "import math\n",
    "import IPython\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.dataFolder = \"./pocketMonsters\"\n",
    "        self.targetShape = (64, 64, 3)\n",
    "        self.batchSize = 64\n",
    "        self.epochs = 100000\n",
    "\n",
    "    #Note in our data generator, we're not doing any image augmentation.\n",
    "    #You could, but you would want to limit yourself to generators that\n",
    "    #retain the look, feel, heart and soul of pocketmonsters.\n",
    "    def loadData(self):\n",
    "        dataset_generator = keras.preprocessing.image.ImageDataGenerator().flow_from_directory(\n",
    "            self.dataFolder, target_size=(self.targetShape[0], self.targetShape[1]),\n",
    "            batch_size=self.batchSize,\n",
    "            class_mode=None)\n",
    "\n",
    "        return dataset_generator\n",
    "\n",
    "    def loadDiscriminator(self):\n",
    "        discriminator = keras.models.Sequential()\n",
    "        discriminator.add(keras.layers.Conv2D(filters=64, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform',\n",
    "                                    input_shape=self.targetShape))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Conv2D(filters=128, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "        discriminator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Conv2D(filters=256, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "        discriminator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Conv2D(filters=512, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "        discriminator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Flatten())\n",
    "        discriminator.add(keras.layers.Dense(1))\n",
    "        discriminator.add(keras.layers.Activation('sigmoid'))\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "        discriminator.compile(loss='binary_crossentropy',\n",
    "                                optimizer=optimizer,\n",
    "                                metrics=None)\n",
    "\n",
    "        return discriminator\n",
    "\n",
    "    def loadGenerator(self):\n",
    "        generator = keras.models.Sequential()\n",
    "        generator.add(keras.layers.Dense(units=4 * 4 * 512,\n",
    "                            kernel_initializer='glorot_uniform',\n",
    "                            input_shape=(1, 1, 100)))\n",
    "        generator.add(keras.layers.Reshape(target_shape=(4, 4, 512)))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.Activation('tanh'))\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=0.00015, beta_1=0.5)\n",
    "        generator.compile(loss='binary_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=None)\n",
    "\n",
    "        return generator\n",
    "\n",
    "    def saveImages(self, genImage, epochNum):\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            grid = gridspec.GridSpec(8, 8)\n",
    "            grid.update(wspace=0.1, hspace=0.1)\n",
    "\n",
    "            for i in range(64):\n",
    "                ax1 = plt.subplot(grid[i])\n",
    "                ax1.set_aspect('equal')\n",
    "                image = genImage[i, :, :, :]\n",
    "\n",
    "                image += 1\n",
    "                image *= 127.5\n",
    "                fig = plt.imshow(image.astype(np.uint8))\n",
    "                plt.axis('off')\n",
    "                fig.axes.get_xaxis().set_visible(False)\n",
    "                fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "            #Small changes to this function for our run: we'll only save\n",
    "            #once every five epochs for speed.\n",
    "            save_name = 'myPokemon/epoch' + str(epochNum + 1) + '.png'\n",
    "            if not os.path.exists('myPokemon'):\n",
    "                os.mkdir('myPokemon')\n",
    "            plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
    "            #We're commenting out this show for now, to let our script run faster.\n",
    "            #We'll just save to a file.\n",
    "            #plt.show()\n",
    "            plt.close()\n",
    "\n",
    "    def loadGAN(self, generator, discriminator):\n",
    "        m = keras.models.Sequential()\n",
    "        discriminator.trainable = False\n",
    "        m.add(generator)\n",
    "        m.add(discriminator)\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=0.00015, beta_1=0.5)\n",
    "        m.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                    metrics=None)\n",
    "        return m\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        #Alright!  Now for the big payoff.\n",
    "        #First, we load our three models - the generator,\n",
    "        #discrimanator, and the GAN that strings the together.\n",
    "        generator = self.loadGenerator()\n",
    "        discriminator = self.loadDiscriminator()\n",
    "        gan = self.loadGAN(generator, discriminator)\n",
    "\n",
    "        # Load our pokemon data\n",
    "        dataGenerator = self.loadData()\n",
    "        \n",
    "        #Calculate the number of batches per epoch required\n",
    "        numBatches = math.ceil(dataGenerator.samples/self.batchSize)\n",
    "\n",
    "        # Save our losses\n",
    "        adversarialLoss = np.empty(shape=1)\n",
    "        discriminatorLoss = np.empty(shape=1)\n",
    "        batches = np.empty(shape=1)\n",
    "\n",
    "        #Let's us show the outputs in Jupyter\n",
    "        plt.ion()\n",
    "\n",
    "        currentBatch = 0\n",
    "\n",
    "        #Training loop starts here!\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"Epoch: \" + str(epoch + 1) + \" of \" + str(self.epochs))\n",
    "            for batchNum in range(numBatches):\n",
    "                startTime = time.time()\n",
    "\n",
    "                #First we load in this batch of real images:\n",
    "                realPokemonImages = dataGenerator.next()\n",
    "\n",
    "                #Here, we normalize to the color scale of the inpt pokemon \n",
    "                #(127.5), and then rescale to between -1 and 1.\n",
    "                #\n",
    "                realPokemonImages /= 127.5\n",
    "                realPokemonImages -= 1\n",
    "\n",
    "                #And calculate how many images we got:\n",
    "                curBatchSize = realPokemonImages.shape[0]\n",
    "\n",
    "                #Here, we generate noise to see our generator (remember the input of 100 on our generators Dense input!)\n",
    "                noise = np.random.normal(0, 1, size=(curBatchSize,) + (1, 1, 100))\n",
    "\n",
    "                #Make our new pokemon\n",
    "                fakePokemonImages = generator.predict(noise)\n",
    "\n",
    "                #We're going to update our discriminator, but don't want to tell it\n",
    "                #exactly what is fake and what is real (as then it would train on our)\n",
    "                #fake images, and we would never be able to fool it.\n",
    "                #So, when we update we update with a \"noisy\" version of our Y, \n",
    "                #in which we randomly label a few true cases as fake,\n",
    "                #and vice-versa.\n",
    "                realPokemon_y = (np.ones(curBatchSize) - np.random.random_sample(curBatchSize) * 0.2)\n",
    "                fakePokemon_y = np.random.random_sample(curBatchSize) * 0.2\n",
    "\n",
    "                #This is where we update the Discriminator.\n",
    "                #We don't allow it to be trained in the adverserial part of the GAN,\n",
    "                #so we must manually do it here.\n",
    "                discriminator.trainable = True\n",
    "\n",
    "                #Here we train with both batches, and then save our loss and turn off\n",
    "                #the discriminator training\n",
    "                discLoss = discriminator.train_on_batch(realPokemonImages, realPokemon_y)\n",
    "                discLoss += discriminator.train_on_batch(fakePokemonImages, fakePokemon_y)\n",
    "\n",
    "                discriminatorLoss = np.append(discriminatorLoss, discLoss)\n",
    "                discriminator.trainable = False\n",
    "\n",
    "\n",
    "                #Now we are going to generate our pokemon!\n",
    "                #Note here we're going to generate 64 \"imaginary\"\n",
    "                #pokemon (i.e., those not living in Williamsburg)\n",
    "                #This number is independent of your batch size - i.e.,\n",
    "                #earlier in the training loop, we created 32 examples\n",
    "                #to train our discriminator - this was so we had the same\n",
    "                #number of real and fake cases.\n",
    "                noise = np.random.normal(0, 1,size=(64,) + (1, 1, 100))\n",
    "\n",
    "                #As before, we are going to assign a fraction of our fake cases to \"true\" cases\n",
    "                #to see how well we can fool the discriminator\n",
    "                fakePokemon_y = (np.ones(64) - np.random.random_sample(64) * 0.2)\n",
    "\n",
    "                #Make the actual images\n",
    "                fakePokemonImages = generator.predict(noise)\n",
    "\n",
    "                gLoss = gan.train_on_batch(noise, fakePokemon_y)\n",
    "                adversarialLoss = np.append(adversarialLoss, gLoss)\n",
    "                batches = np.append(batches, currentBatch)                    \n",
    "                \n",
    "                timeElapsed = time.time() - startTime\n",
    "                print(\"Epoch\" + str(epoch) + \" Batch \" + str(batchNum + 1) + \" of \" + str(numBatches) + \" | Generator Loss: \" + str(round(gLoss, 3)) + \" | Discriminator Loss: \" + str(round(discLoss, 3)) + \" | Time: \" + str(timeElapsed) + \" seconds.\")\n",
    "\n",
    "\n",
    "                currentBatch += 1\n",
    "\n",
    "            # Regularly save model weights and images\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                discriminator.trainable = True\n",
    "                if not os.path.exists('models'):\n",
    "                    os.mkdir('models')\n",
    "                generator.save('models/genEpoch' + str(epoch) + '.hdf5')\n",
    "                discriminator.save('models/discEpoch' + str(epoch) + '.hdf5')\n",
    "                self.saveImages(fakePokemonImages, epoch)\n",
    "\n",
    "            # Update our loss graph\n",
    "            plt.figure(1)\n",
    "            plt.plot(batches, adversarialLoss, color='green',\n",
    "                     label='Generator Loss')\n",
    "            plt.plot(batches, discriminatorLoss, color='blue',\n",
    "                     label='Discriminator Loss')\n",
    "            plt.title(\"GAN Training\")\n",
    "            plt.xlabel(\"Batch Iteration\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            if epoch == 0:\n",
    "                plt.legend()\n",
    "            plt.savefig('trainingLossPlot.png')\n",
    "            plt.close()\n",
    "\n",
    "\n",
    "dataset_path = './pocketMonsters'\n",
    "batch_size = 64\n",
    "image_shape = (64, 64, 3)\n",
    "epochs = 45\n",
    "makePokemon = GAN()\n",
    "makePokemon.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}