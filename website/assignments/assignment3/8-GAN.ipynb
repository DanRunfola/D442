{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd08e3a21d38ab9816cf2a4fb5b70910b2de32092d7fedca6365d5651d786256744",
   "display_name": "Python 3.8.5 64-bit ('data442': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "8e3a21d38ab9816cf2a4fb5b70910b2de32092d7fedca6365d5651d786256744"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1171 images belonging to 2 classes.\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"250.618594pt\" version=\"1.1\" viewBox=\"0 0 251.565 250.618594\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <metadata>\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\n   <cc:Work>\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\n    <dc:date>2021-04-09T16:53:21.486881</dc:date>\n    <dc:format>image/svg+xml</dc:format>\n    <dc:creator>\n     <cc:Agent>\n      <dc:title>Matplotlib v3.3.3, https://matplotlib.org/</dc:title>\n     </cc:Agent>\n    </dc:creator>\n   </cc:Work>\n  </rdf:RDF>\n </metadata>\n <defs>\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 250.618594 \nL 251.565 250.618594 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 226.740469 \nL 244.365 226.740469 \nL 244.365 9.300469 \nL 26.925 9.300469 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p8205fb6687)\">\n    <image height=\"218\" id=\"imageea21a3bd05\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\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\" y=\"-8.740469\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m2a1c55af9b\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"28.62375\" xlink:href=\"#m2a1c55af9b\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <g transform=\"translate(25.4425 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"62.59875\" xlink:href=\"#m2a1c55af9b\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 10 -->\n      <g transform=\"translate(56.23625 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"96.57375\" xlink:href=\"#m2a1c55af9b\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 20 -->\n      <g transform=\"translate(90.21125 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"130.54875\" xlink:href=\"#m2a1c55af9b\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 30 -->\n      <g transform=\"translate(124.18625 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 40.578125 39.3125 \nQ 47.65625 37.796875 51.625 33 \nQ 55.609375 28.21875 55.609375 21.1875 \nQ 55.609375 10.40625 48.1875 4.484375 \nQ 40.765625 -1.421875 27.09375 -1.421875 \nQ 22.515625 -1.421875 17.65625 -0.515625 \nQ 12.796875 0.390625 7.625 2.203125 \nL 7.625 11.71875 \nQ 11.71875 9.328125 16.59375 8.109375 \nQ 21.484375 6.890625 26.8125 6.890625 \nQ 36.078125 6.890625 40.9375 10.546875 \nQ 45.796875 14.203125 45.796875 21.1875 \nQ 45.796875 27.640625 41.28125 31.265625 \nQ 36.765625 34.90625 28.71875 34.90625 \nL 20.21875 34.90625 \nL 20.21875 43.015625 \nL 29.109375 43.015625 \nQ 36.375 43.015625 40.234375 45.921875 \nQ 44.09375 48.828125 44.09375 54.296875 \nQ 44.09375 59.90625 40.109375 62.90625 \nQ 36.140625 65.921875 28.71875 65.921875 \nQ 24.65625 65.921875 20.015625 65.03125 \nQ 15.375 64.15625 9.8125 62.3125 \nL 9.8125 71.09375 \nQ 15.4375 72.65625 20.34375 73.4375 \nQ 25.25 74.21875 29.59375 74.21875 \nQ 40.828125 74.21875 47.359375 69.109375 \nQ 53.90625 64.015625 53.90625 55.328125 \nQ 53.90625 49.265625 50.4375 45.09375 \nQ 46.96875 40.921875 40.578125 39.3125 \nz\n\" id=\"DejaVuSans-51\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"164.52375\" xlink:href=\"#m2a1c55af9b\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 40 -->\n      <g transform=\"translate(158.16125 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 37.796875 64.3125 \nL 12.890625 25.390625 \nL 37.796875 25.390625 \nz\nM 35.203125 72.90625 \nL 47.609375 72.90625 \nL 47.609375 25.390625 \nL 58.015625 25.390625 \nL 58.015625 17.1875 \nL 47.609375 17.1875 \nL 47.609375 0 \nL 37.796875 0 \nL 37.796875 17.1875 \nL 4.890625 17.1875 \nL 4.890625 26.703125 \nz\n\" id=\"DejaVuSans-52\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"198.49875\" xlink:href=\"#m2a1c55af9b\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 50 -->\n      <g transform=\"translate(192.13625 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_7\">\n     <g id=\"line2d_7\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"232.47375\" xlink:href=\"#m2a1c55af9b\" y=\"226.740469\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 60 -->\n      <g transform=\"translate(226.11125 241.338906)scale(0.1 -0.1)\">\n       <defs>\n        <path d=\"M 33.015625 40.375 \nQ 26.375 40.375 22.484375 35.828125 \nQ 18.609375 31.296875 18.609375 23.390625 \nQ 18.609375 15.53125 22.484375 10.953125 \nQ 26.375 6.390625 33.015625 6.390625 \nQ 39.65625 6.390625 43.53125 10.953125 \nQ 47.40625 15.53125 47.40625 23.390625 \nQ 47.40625 31.296875 43.53125 35.828125 \nQ 39.65625 40.375 33.015625 40.375 \nz\nM 52.59375 71.296875 \nL 52.59375 62.3125 \nQ 48.875 64.0625 45.09375 64.984375 \nQ 41.3125 65.921875 37.59375 65.921875 \nQ 27.828125 65.921875 22.671875 59.328125 \nQ 17.53125 52.734375 16.796875 39.40625 \nQ 19.671875 43.65625 24.015625 45.921875 \nQ 28.375 48.1875 33.59375 48.1875 \nQ 44.578125 48.1875 50.953125 41.515625 \nQ 57.328125 34.859375 57.328125 23.390625 \nQ 57.328125 12.15625 50.6875 5.359375 \nQ 44.046875 -1.421875 33.015625 -1.421875 \nQ 20.359375 -1.421875 13.671875 8.265625 \nQ 6.984375 17.96875 6.984375 36.375 \nQ 6.984375 53.65625 15.1875 63.9375 \nQ 23.390625 74.21875 37.203125 74.21875 \nQ 40.921875 74.21875 44.703125 73.484375 \nQ 48.484375 72.75 52.59375 71.296875 \nz\n\" id=\"DejaVuSans-54\"/>\n       </defs>\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_8\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m48533faf73\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m48533faf73\" y=\"10.999219\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.798437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m48533faf73\" y=\"44.974219\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 48.773437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m48533faf73\" y=\"78.949219\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 82.748437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m48533faf73\" y=\"112.924219\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 30 -->\n      <g transform=\"translate(7.2 116.723437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-51\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m48533faf73\" y=\"146.899219\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 40 -->\n      <g transform=\"translate(7.2 150.698437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-52\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_13\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m48533faf73\" y=\"180.874219\"/>\n      </g>\n     </g>\n     <g id=\"text_13\">\n      <!-- 50 -->\n      <g transform=\"translate(7.2 184.673437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_7\">\n     <g id=\"line2d_14\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m48533faf73\" y=\"214.849219\"/>\n      </g>\n     </g>\n     <g id=\"text_14\">\n      <!-- 60 -->\n      <g transform=\"translate(7.2 218.648437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-54\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 226.740469 \nL 26.925 9.300469 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 226.740469 \nL 244.365 9.300469 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 226.740469 \nL 244.365 226.740469 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 9.300469 \nL 244.365 9.300469 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p8205fb6687\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"9.300469\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "#In this notebook, you'll learn how to implement a Generative Adversarial Network (GAN).\n",
    "#The goal of a GAN is to create one network - a \"Generator\" - which seeks to create pictures\n",
    "#of something (in our case - pokemon); the second network is a \"Discriminator\", which examines\n",
    "#our generated pictures and tries to determine if they are fake or real.\n",
    "#The generator network learns over multiple iterations to \"fool\" the discriminator - \n",
    "#hopefully creating some powerful pokemon!\n",
    "#Note GANs are data hungry, so I'm combining gen1 and gen2 pokemon.  Blasphemy, I know.\n",
    "\n",
    "#(Also Note - Pokemon are a very popular starting point for GAN.  For all sorts of implementations, \n",
    "#search for \"PokeGAN\").\n",
    "\n",
    "import keras\n",
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "#We're going to implement our GAN as a class, mostly so as to keep our sanity!\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.dataFolder = \"./pocketMonsters\"\n",
    "        self.targetShape = (64, 64, 3)\n",
    "        self.batchSize = 64\n",
    "        self.epochs = 100\n",
    "\n",
    "    #Note in our data generator, we're not doing any image augmentation.\n",
    "    #You could, but you would want to limit yourself to generators that\n",
    "    #retain the look, feel, heart and soul of pocketmonsters.\n",
    "    def loadData(self):\n",
    "        dataset_generator = keras.preprocessing.image.ImageDataGenerator(samplewise_center=True).flow_from_directory(\n",
    "            self.dataFolder, target_size=(self.targetShape[0], self.targetShape[1]),\n",
    "            batch_size=self.batchSize,\n",
    "            class_mode=None)\n",
    "\n",
    "        return dataset_generator\n",
    "\n",
    "pokeGAN = GAN()\n",
    "\n",
    "train = pokeGAN.loadData()                                    \n",
    "\n",
    "plt.imshow(next(train)[10].astype('uint8'))\n",
    "plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_7\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nconv2d_12 (Conv2D)           (None, 32, 32, 64)        4864      \n_________________________________________________________________\nleaky_re_lu_12 (LeakyReLU)   (None, 32, 32, 64)        0         \n_________________________________________________________________\nconv2d_13 (Conv2D)           (None, 16, 16, 128)       204928    \n_________________________________________________________________\nbatch_normalization_17 (Batc (None, 16, 16, 128)       512       \n_________________________________________________________________\nleaky_re_lu_13 (LeakyReLU)   (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d_14 (Conv2D)           (None, 8, 8, 256)         819456    \n_________________________________________________________________\nbatch_normalization_18 (Batc (None, 8, 8, 256)         1024      \n_________________________________________________________________\nleaky_re_lu_14 (LeakyReLU)   (None, 8, 8, 256)         0         \n_________________________________________________________________\nconv2d_15 (Conv2D)           (None, 4, 4, 512)         3277312   \n_________________________________________________________________\nbatch_normalization_19 (Batc (None, 4, 4, 512)         2048      \n_________________________________________________________________\nleaky_re_lu_15 (LeakyReLU)   (None, 4, 4, 512)         0         \n_________________________________________________________________\nflatten_3 (Flatten)          (None, 8192)              0         \n_________________________________________________________________\ndense_5 (Dense)              (None, 1)                 8193      \n_________________________________________________________________\nactivation_13 (Activation)   (None, 1)                 0         \n=================================================================\nTotal params: 4,318,337\nTrainable params: 4,316,545\nNon-trainable params: 1,792\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.dataFolder = \"./pocketMonsters\"\n",
    "        self.targetShape = (64, 64, 3)\n",
    "        self.batchSize = 64\n",
    "        self.epochs = 100\n",
    "\n",
    "    def loadData(self):\n",
    "        dataset_generator = ImageDataGenerator().flow_from_directory(\n",
    "            self.dataFolder, target_size=(self.targetShape[0], self.targetShape[1]),\n",
    "            batch_size=self.batchSize,\n",
    "            class_mode=None)\n",
    "\n",
    "        return dataset_generator\n",
    "\n",
    "    #Next up: our descrimanator!  The basic idea of the GAN is to have a model\n",
    "    #that checks if an image is real, and train another model (the generator)\n",
    "    #on that model.  Here, we're creating the descriminator - i.e., the model\n",
    "    #that checks if something is real or not.\n",
    "    #For now we're just going to define it here - in a few cells, we'll take a look at how\n",
    "    #we train it.\n",
    "    def loadDescriminator(self):\n",
    "        discriminator = keras.models.Sequential()\n",
    "        discriminator.add(keras.layers.Conv2D(filters=64, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform',\n",
    "                                    input_shape=self.targetShape))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Conv2D(filters=128, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "        discriminator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Conv2D(filters=256, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "        discriminator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Conv2D(filters=512, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "        discriminator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Flatten())\n",
    "        discriminator.add(keras.layers.Dense(1))\n",
    "        discriminator.add(keras.layers.Activation('sigmoid'))\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "        discriminator.compile(loss='binary_crossentropy',\n",
    "                                optimizer=optimizer,\n",
    "                                metrics=None)\n",
    "\n",
    "        return discriminator\n",
    "\n",
    "pokeGAN = GAN()\n",
    "\n",
    "model = pokeGAN.loadDescriminator() \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_8\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense_6 (Dense)              (None, 1, 1, 8192)        827392    \n_________________________________________________________________\nreshape_2 (Reshape)          (None, 4, 4, 512)         0         \n_________________________________________________________________\nbatch_normalization_20 (Batc (None, 4, 4, 512)         2048      \n_________________________________________________________________\nactivation_14 (Activation)   (None, 4, 4, 512)         0         \n_________________________________________________________________\nconv2d_transpose_8 (Conv2DTr (None, 8, 8, 256)         3277056   \n_________________________________________________________________\nbatch_normalization_21 (Batc (None, 8, 8, 256)         1024      \n_________________________________________________________________\nactivation_15 (Activation)   (None, 8, 8, 256)         0         \n_________________________________________________________________\nconv2d_transpose_9 (Conv2DTr (None, 16, 16, 128)       819328    \n_________________________________________________________________\nbatch_normalization_22 (Batc (None, 16, 16, 128)       512       \n_________________________________________________________________\nactivation_16 (Activation)   (None, 16, 16, 128)       0         \n_________________________________________________________________\nconv2d_transpose_10 (Conv2DT (None, 32, 32, 64)        204864    \n_________________________________________________________________\nbatch_normalization_23 (Batc (None, 32, 32, 64)        256       \n_________________________________________________________________\nactivation_17 (Activation)   (None, 32, 32, 64)        0         \n_________________________________________________________________\nconv2d_transpose_11 (Conv2DT (None, 64, 64, 3)         4803      \n_________________________________________________________________\nactivation_18 (Activation)   (None, 64, 64, 3)         0         \n=================================================================\nTotal params: 5,137,283\nTrainable params: 5,135,363\nNon-trainable params: 1,920\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.dataFolder = \"./pocketMonsters\"\n",
    "        self.targetShape = (64, 64, 3)\n",
    "        self.batchSize = 64\n",
    "        self.epochs = 100\n",
    "\n",
    "    #And, here is our generator.  This is a model that attempts\n",
    "    #to create images that will fool the discriminator.\n",
    "    #Again, we'll use this in a few cells to show how it works.\n",
    "    #Of note is the input_shape for the first dense layer -\n",
    "    #this is going to represent an input of random noise\n",
    "    #that we're using to initialize the generator.\n",
    "    def loadGenerator(self):\n",
    "        generator = keras.models.Sequential()\n",
    "        generator.add(keras.layers.Dense(units=4 * 4 * 512,\n",
    "                            kernel_initializer='glorot_uniform',\n",
    "                            input_shape=(1, 1, 100)))\n",
    "        generator.add(keras.layers.Reshape(target_shape=(4, 4, 512)))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.Activation('tanh'))\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=0.00015, beta_1=0.5)\n",
    "        generator.compile(loss='binary_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=None)\n",
    "\n",
    "        return generator\n",
    "\n",
    "pokeGAN = GAN()\n",
    "\n",
    "model = pokeGAN.loadGenerator() \n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.dataFolder = \"./pocketMonsters\"\n",
    "        self.targetShape = (64, 64, 3)\n",
    "        self.batchSize = 64\n",
    "        self.epochs = 100\n",
    "\n",
    "    #Next up is a small helper function so we can see how the images evolve\n",
    "    #across epochs:\n",
    "    def saveImages(self, genImage, epochNum, batchNum):\n",
    "            #We're generating 64 pokemon each iteration:\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            grid = gridspec.GridSpec(8, 8)\n",
    "            grid.update(wspace=0.1, hspace=0.1)\n",
    "\n",
    "            for i in range(64):\n",
    "                ax1 = plt.subplot(grid[i])\n",
    "                ax1.set_aspect('equal')\n",
    "                image = generated_images[i, :, :, :]\n",
    "\n",
    "                #Scale colors between 1 and 255\n",
    "                image += 1\n",
    "                image *= 255\n",
    "                fig = plt.imshow(image.astype(np.uint8))\n",
    "                plt.axis('off')\n",
    "                fig.axes.get_xaxis().set_visible(False)\n",
    "                fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            save_name = 'myPokemon/epoch' + str(epoch_no + 1) + 'Batch' + str(batch_no + 1) + '.png'\n",
    "            if not os.path.exists('myPokemon'):\n",
    "                os.mkdir('myPokemon')\n",
    "            plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.dataFolder = \"./pocketMonsters\"\n",
    "        self.targetShape = (64, 64, 3)\n",
    "        self.batchSize = 64\n",
    "        self.epochs = 100\n",
    "\n",
    "    #Now we need to define how the generator and dicriminator\n",
    "    #will interact, and how we'll optimize them.  This is \n",
    "    #the GAN itself.\n",
    "    def loadGAN(self, generator, discriminator):\n",
    "        m = keras.models.Sequential()\n",
    "        discriminator.trainable = False\n",
    "        m.add(generator)\n",
    "        m.add(discriminator)\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=0.00015, beta_1=0.5)\n",
    "        m.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                    metrics=None)\n",
    "        return m\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 1171 images belonging to 2 classes.\n",
      "Epoch: 1 of 100\n",
      " Batch 1 of 19 | Generator Loss: 0.55 | Discriminator Loss: 6.313 | Time: 1.3861753940582275 seconds.\n",
      " Batch 2 of 19 | Generator Loss: 0.957 | Discriminator Loss: 1.512 | Time: 0.4784235954284668 seconds.\n",
      " Batch 3 of 19 | Generator Loss: 2.436 | Discriminator Loss: 5.505 | Time: 0.7734451293945312 seconds.\n",
      " Batch 4 of 19 | Generator Loss: 2.837 | Discriminator Loss: 2.382 | Time: 0.5299167633056641 seconds.\n",
      " Batch 5 of 19 | Generator Loss: 2.695 | Discriminator Loss: 1.213 | Time: 0.5787930488586426 seconds.\n",
      " Batch 6 of 19 | Generator Loss: 3.6 | Discriminator Loss: 8.131 | Time: 0.6775360107421875 seconds.\n",
      " Batch 7 of 19 | Generator Loss: 3.371 | Discriminator Loss: 3.128 | Time: 0.5413310527801514 seconds.\n",
      " Batch 8 of 19 | Generator Loss: 3.504 | Discriminator Loss: 2.506 | Time: 0.5175213813781738 seconds.\n",
      " Batch 9 of 19 | Generator Loss: 3.705 | Discriminator Loss: 1.428 | Time: 0.6498546600341797 seconds.\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'generated_images' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2233c94abe64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m45\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0mmakePokemon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGAN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 272\u001b[0;31m \u001b[0mmakePokemon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-2233c94abe64>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m                 \u001b[0;31m#(We skip any batches that have partial numbers of pokemon, i.e. not the full batch of 32)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatchNum\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m10\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcurBatchSize\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaveImages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfakePokemonImages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchNum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m                 \u001b[0mtimeElapsed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstartTime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-26-2233c94abe64>\u001b[0m in \u001b[0;36msaveImages\u001b[0;34m(self, genImage, epochNum, batchNum)\u001b[0m\n\u001b[1;32m    121\u001b[0m                 \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                 \u001b[0max1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_aspect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'equal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                 \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerated_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0mimage\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generated_images' is not defined"
     ]
    }
   ],
   "source": [
    "#Finally, we add everything together into a mega-Class.\n",
    "#The real heavy lifting is in the final method here - our training method!\n",
    "#Running this cell will build our GAN.\n",
    "\n",
    "import time\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import numpy as np\n",
    "import keras\n",
    "import math\n",
    "\n",
    "class GAN:\n",
    "    def __init__(self):\n",
    "        self.dataFolder = \"./pocketMonsters\"\n",
    "        self.targetShape = (64, 64, 3)\n",
    "        self.batchSize = 64\n",
    "        self.epochs = 10000\n",
    "\n",
    "    #Note in our data generator, we're not doing any image augmentation.\n",
    "    #You could, but you would want to limit yourself to generators that\n",
    "    #retain the look, feel, heart and soul of pocketmonsters.\n",
    "    def loadData(self):\n",
    "        dataset_generator = keras.preprocessing.image.ImageDataGenerator(samplewise_center=True).flow_from_directory(\n",
    "            self.dataFolder, target_size=(self.targetShape[0], self.targetShape[1]),\n",
    "            batch_size=self.batchSize,\n",
    "            class_mode=None)\n",
    "\n",
    "        return dataset_generator\n",
    "\n",
    "    def loadDiscriminator(self):\n",
    "        discriminator = keras.models.Sequential()\n",
    "        discriminator.add(keras.layers.Conv2D(filters=64, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform',\n",
    "                                    input_shape=self.targetShape))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Conv2D(filters=128, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "        discriminator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Conv2D(filters=256, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "        discriminator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Conv2D(filters=512, kernel_size=(5, 5),\n",
    "                                    strides=(2, 2), padding='same',\n",
    "                                    data_format='channels_last',\n",
    "                                    kernel_initializer='glorot_uniform'))\n",
    "        discriminator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        discriminator.add(keras.layers.LeakyReLU(0.2))\n",
    "\n",
    "        discriminator.add(keras.layers.Flatten())\n",
    "        discriminator.add(keras.layers.Dense(1))\n",
    "        discriminator.add(keras.layers.Activation('sigmoid'))\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=0.0002, beta_1=0.5)\n",
    "        discriminator.compile(loss='binary_crossentropy',\n",
    "                                optimizer=optimizer,\n",
    "                                metrics=None)\n",
    "\n",
    "        return discriminator\n",
    "\n",
    "    def loadGenerator(self):\n",
    "        generator = keras.models.Sequential()\n",
    "        generator.add(keras.layers.Dense(units=4 * 4 * 512,\n",
    "                            kernel_initializer='glorot_uniform',\n",
    "                            input_shape=(1, 1, 100)))\n",
    "        generator.add(keras.layers.Reshape(target_shape=(4, 4, 512)))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=256, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=128, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=64, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.BatchNormalization(momentum=0.5))\n",
    "        generator.add(keras.layers.Activation('relu'))\n",
    "\n",
    "        generator.add(keras.layers.Conv2DTranspose(filters=3, kernel_size=(5, 5),\n",
    "                                      strides=(2, 2), padding='same',\n",
    "                                      data_format='channels_last',\n",
    "                                      kernel_initializer='glorot_uniform'))\n",
    "        generator.add(keras.layers.Activation('tanh'))\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=0.00015, beta_1=0.5)\n",
    "        generator.compile(loss='binary_crossentropy',\n",
    "                          optimizer=optimizer,\n",
    "                          metrics=None)\n",
    "\n",
    "        return generator\n",
    "\n",
    "    def saveImages(self, genImage, epochNum, batchNum):\n",
    "            plt.figure(figsize=(8, 8))\n",
    "            grid = gridspec.GridSpec(8, 8)\n",
    "            grid.update(wspace=0.1, hspace=0.1)\n",
    "\n",
    "            for i in range(64):\n",
    "                ax1 = plt.subplot(grid[i])\n",
    "                ax1.set_aspect('equal')\n",
    "                image = genImage[i, :, :, :]\n",
    "\n",
    "                image += 1\n",
    "                image *= 255\n",
    "                fig = plt.imshow(image.astype(np.uint8))\n",
    "                plt.axis('off')\n",
    "                fig.axes.get_xaxis().set_visible(False)\n",
    "                fig.axes.get_yaxis().set_visible(False)\n",
    "\n",
    "            plt.tight_layout()\n",
    "            save_name = 'myPokemon/epoch' + str(epochNum + 1) + 'Batch' + str(batchNum + 1) + '.png'\n",
    "            if not os.path.exists('myPokemon'):\n",
    "                os.mkdir('myPokemon')\n",
    "            plt.savefig(save_name, bbox_inches='tight', pad_inches=0)\n",
    "            plt.show()\n",
    "\n",
    "    def loadGAN(self, generator, discriminator):\n",
    "        m = keras.models.Sequential()\n",
    "        discriminator.trainable = False\n",
    "        m.add(generator)\n",
    "        m.add(discriminator)\n",
    "\n",
    "        optimizer = keras.optimizers.Adam(lr=0.00015, beta_1=0.5)\n",
    "        m.compile(loss='binary_crossentropy', optimizer=optimizer,\n",
    "                    metrics=None)\n",
    "        return m\n",
    "\n",
    "\n",
    "    def train(self):\n",
    "        #Alright!  Now for the big payoff.\n",
    "        #First, we load our three models - the generator,\n",
    "        #discrimanator, and the GAN that strings the together.\n",
    "        generator = self.loadGenerator()\n",
    "        discriminator = self.loadDiscriminator()\n",
    "        gan = self.loadGAN(generator, discriminator)\n",
    "\n",
    "        # Load our pokemon data\n",
    "        dataGenerator = self.loadData()\n",
    "        \n",
    "        #Calculate the number of batches per epoch required\n",
    "        numBatches = math.ceil(dataGenerator.samples/self.batchSize)\n",
    "\n",
    "        # Save our losses\n",
    "        adversarialLoss = np.empty(shape=1)\n",
    "        discriminatorLoss = np.empty(shape=1)\n",
    "        batches = np.empty(shape=1)\n",
    "\n",
    "        #Let's us show the outputs in Jupyter\n",
    "        plt.ion()\n",
    "\n",
    "        currentBatch = 0\n",
    "\n",
    "        #Training loop starts here!\n",
    "        for epoch in range(self.epochs):\n",
    "            print(\"Epoch: \" + str(epoch + 1) + \" of \" + str(self.epochs))\n",
    "            for batchNum in range(numBatches):\n",
    "                startTime = time.time()\n",
    "\n",
    "                #First we load in this batch of real images:\n",
    "                realPokemonImages = dataGenerator.next()\n",
    "                #And calculate how many images we got:\n",
    "                curBatchSize = realPokemonImages.shape[0]\n",
    "\n",
    "                #Here, we generate noise to see our generator (remember the input of 100 on our generators Dense input!)\n",
    "                noise = np.random.normal(0, 1, size=(curBatchSize,) + (1, 1, 100))\n",
    "\n",
    "                #Make our new pokemon\n",
    "                fakePokemonImages = generator.predict(noise)\n",
    "\n",
    "                #We're going to update our discriminator, but don't want to tell it\n",
    "                #exactly what is fake and what is real (as then it would train on our)\n",
    "                #fake images, and we would never be able to fool it.\n",
    "                #So, when we update we update with a \"noisy\" version of our Y, \n",
    "                #in which we randomly label a few true cases as fake,\n",
    "                #and vice-versa.\n",
    "                realPokemon_y = (np.ones(curBatchSize) - np.random.random_sample(curBatchSize) * 0.2)\n",
    "                fakePokemon_y = np.random.random_sample(curBatchSize) * 0.2\n",
    "\n",
    "                #This is where we update the Discriminator.\n",
    "                #We don't allow it to be trained in the adverserial part of the GAN,\n",
    "                #so we must manually do it here.\n",
    "                discriminator.trainable = True\n",
    "\n",
    "                #Here we train with both batches, and then save our loss and turn off\n",
    "                #the discriminator training\n",
    "                discLoss = discriminator.train_on_batch(realPokemonImages, realPokemon_y)\n",
    "                discLoss += discriminator.train_on_batch(fakePokemonImages, fakePokemon_y)\n",
    "\n",
    "                discriminatorLoss = np.append(discriminatorLoss, discLoss)\n",
    "                discriminator.trainable = False\n",
    "\n",
    "\n",
    "                #Now we are going to generate our pokemon!\n",
    "                #Note here we're going to generate 64 \"imaginary\"\n",
    "                #pokemon (i.e., those not living in Williamsburg)\n",
    "                #This number is independent of your batch size - i.e.,\n",
    "                #earlier in the training loop, we created 32 examples\n",
    "                #to train our discriminator - this was so we had the same\n",
    "                #number of real and fake cases.\n",
    "                noise = np.random.normal(0, 1,size=(64,) + (1, 1, 100))\n",
    "\n",
    "                #As before, we are going to assign a fraction of our fake cases to \"true\" cases\n",
    "                #to see how well we can fool the discriminator\n",
    "                fakePokemon_y = (np.ones(64) - np.random.random_sample(64) * 0.2)\n",
    "\n",
    "                gLoss = gan.train_on_batch(noise, fakePokemon_y)\n",
    "                adversarialLoss = np.append(adversarialLoss, gLoss)\n",
    "                batches = np.append(batches, currentBatch)\n",
    "\n",
    "                #Use our visualization function to show off our pokemon\n",
    "                #(We skip any batches that have partial numbers of pokemon, i.e. not the full batch of 32)\n",
    "                if ((batchNum + 1) % 10 == 0 and curBatchSize == self.batchSize):\n",
    "                    self.saveImages(fakePokemonImages, epoch, batchNum)\n",
    "\n",
    "                timeElapsed = time.time() - startTime\n",
    "\n",
    "                # Display and plot the results\n",
    "                print(\" Batch \" + str(batchNum + 1) + \" of \" + str(numBatches) + \" | Generator Loss: \" + str(round(gLoss, 3)) + \" | Discriminator Loss: \" + str(round(discLoss, 3)) + \" | Time: \" + str(timeElapsed) + \" seconds.\")\n",
    "\n",
    "                currentBatch += 1\n",
    "\n",
    "            # Save the model weights each 5 epochs\n",
    "            if (epoch + 1) % 5 == 0:\n",
    "                discriminator.trainable = True\n",
    "                if not os.path.exists('models'):\n",
    "                    os.mkdir('models')\n",
    "                generator.save('models/genEpoch' + str(epoch) + '.hdf5')\n",
    "                discriminator.save('models/discEpoch' + str(epoch) + '.hdf5')\n",
    "\n",
    "            # Each epoch update the loss graphs\n",
    "            plt.figure(1)\n",
    "            plt.plot(batches, adversarialLoss, color='green',\n",
    "                     label='Generator Loss')\n",
    "            plt.plot(batches, discriminatorLoss, color='blue',\n",
    "                     label='Discriminator Loss')\n",
    "            plt.title(\"GAN Training\")\n",
    "            plt.xlabel(\"Batch Iteration\")\n",
    "            plt.ylabel(\"Loss\")\n",
    "            if epoch == 0:\n",
    "                plt.legend()\n",
    "            plt.show()\n",
    "            plt.savefig('trainingLossPlot.png')\n",
    "\n",
    "\n",
    "dataset_path = './pocketMonsters'\n",
    "batch_size = 64\n",
    "image_shape = (64, 64, 3)\n",
    "epochs = 45\n",
    "makePokemon = GAN()\n",
    "makePokemon.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}